{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d162b6bb-04be-41c3-94af-44ab59e6500d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00c0043-c7ca-4492-ad2f-cced9d6fae30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2e3631-6704-4cac-8a49-88743235ff8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in 'company_name' column: 8971\n",
      "Number of unique values in 'status_label' column: 2\n",
      "Number of unique values in 'Division' column: 10\n",
      "Number of unique values in 'MajorGroup' column: 73\n",
      "Number of unique values in 'last_year' column: 20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data set\n",
    "data = pd.read_csv(\"new_df_selected5_last5years_adjusted.csv\")\n",
    "\n",
    "unique_company_names = data['company_name'].nunique()\n",
    "unique_status_labels = data['status_label'].nunique()\n",
    "unique_divisions = data['Division'].nunique()\n",
    "unique_majorgroup = data['MajorGroup'].nunique()\n",
    "unique_last_year = data['last_year'].nunique()\n",
    "\n",
    "print(\"Number of unique values in 'company_name' column:\", unique_company_names)\n",
    "print(\"Number of unique values in 'status_label' column:\", unique_status_labels)\n",
    "print(\"Number of unique values in 'Division' column:\", unique_divisions)\n",
    "print(\"Number of unique values in 'MajorGroup' column:\", unique_majorgroup)\n",
    "print(\"Number of unique values in 'last_year' column:\", unique_last_year)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263fa8e8-cf02-4f9e-a23d-74af29abb22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0552208d-295c-4128-90b8-ed6e4d3a1494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8971 entries, 0 to 8970\n",
      "Columns: 195 entries, company_name to nasdaq_last5year\n",
      "dtypes: float64(191), int64(1), object(3)\n",
      "memory usage: 13.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc4a5663-66c6-4f87-84bb-ff9ab875eba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  company_name status_label Division  MajorGroup  last_year  X1_last1year  \\\n",
      "0          C_1        alive        D          37     2017.0         942.7   \n",
      "1          C_2        alive        D          36     2010.0        1107.7   \n",
      "2          C_3        alive        D          38     2008.0       12686.0   \n",
      "3          C_4        alive        D          28     2007.0      581502.0   \n",
      "4          C_5        alive        D          35     1999.0       28957.0   \n",
      "\n",
      "   X1_last2year  X1_last3year  X1_last4year  X1_last5year  ...  \\\n",
      "0         888.5         873.1         954.1      1116.900  ...   \n",
      "1         900.2        1077.4        1008.2       942.700  ...   \n",
      "2       13454.0       13582.0        7726.0      5807.000  ...   \n",
      "3      353541.0     1037047.0      672072.0       692.991  ...   \n",
      "4           NaN           NaN           NaN           NaN  ...   \n",
      "\n",
      "   nyse_last5year  nasdaq_last1year  nasdaq_last2year  nasdaq_last3year  \\\n",
      "0     9467.185872       6293.024211       5015.926717       4932.729126   \n",
      "1     8434.441610       2333.908345       1856.529999       2148.948334   \n",
      "2     6645.525065       2148.948334       2587.587504       2278.996664   \n",
      "3     5478.855835       2587.587504       2278.996664       2100.603343   \n",
      "4             NaN       2787.559998               NaN               NaN   \n",
      "\n",
      "   nasdaq_last4year  nasdaq_last5year  company_name_encoded  Division_encoded  \\\n",
      "0       4414.850057       3575.141642                     0                 3   \n",
      "1       2587.587504       2278.996664                  1111                 3   \n",
      "2       2100.603343       1992.867482                  2222                 3   \n",
      "3       1992.867482       1659.239176                  3333                 3   \n",
      "4               NaN               NaN                  4444                 3   \n",
      "\n",
      "   MajorGroup_encoded  status_label_encoded  \n",
      "0                  29                     0  \n",
      "1                  28                     0  \n",
      "2                  30                     0  \n",
      "3                  20                     0  \n",
      "4                  27                     0  \n",
      "\n",
      "[5 rows x 199 columns]\n"
     ]
    }
   ],
   "source": [
    "# Encoding non-numeric columns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "# Label-encode the company_name column\n",
    "data['company_name_encoded'] = label_encoder.fit_transform(data['company_name'])\n",
    "\n",
    "\n",
    "# Label-encode the Division column\n",
    "data['Division_encoded'] = label_encoder.fit_transform(data['Division'])\n",
    "\n",
    "# Label-encode MajorGroup columns\n",
    "data['MajorGroup_encoded'] = label_encoder.fit_transform(data['MajorGroup'])\n",
    "#When using label encoding for feature encoding, the sequential relationship between categories will not be introduced and will not have an impact on prediction.\n",
    "\n",
    "# Encode the label of the status_label column\n",
    "data['status_label_encoded'] = label_encoder.fit_transform(data['status_label'])\n",
    "#With only two categories, it may be simpler and more appropriate to use label encoding as it maps the categories to 0 and 1, suitable for use in tree-based models. \n",
    "#If use one-hot encoding, a new column will be generated\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1f286d3-0047-4da4-90dc-dd63a2e84a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8971 entries, 0 to 8970\n",
      "Columns: 199 entries, company_name to status_label_encoded\n",
      "dtypes: float64(191), int32(3), int64(2), object(3)\n",
      "memory usage: 13.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "374fe89d-42d2-472f-8724-dcc6f06dff33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8971, 199)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b45588-522a-4d3c-8509-9749f7d3c4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in 'company_name_encoded' column: 8971\n",
      "Number of unique values in 'status_label_encoded' column: 2\n",
      "Number of unique values in 'Division_encoded' column: 10\n",
      "Number of unique values in 'MajorGroup_encoded' column: 73\n"
     ]
    }
   ],
   "source": [
    "unique_company_names = data['company_name_encoded'].nunique()\n",
    "unique_status_labels = data['status_label_encoded'].nunique()\n",
    "unique_divisions = data['Division_encoded'].nunique()\n",
    "unique_majorgroup = data['MajorGroup_encoded'].nunique()\n",
    "\n",
    "print(\"Number of unique values in 'company_name_encoded' column:\", unique_company_names)\n",
    "print(\"Number of unique values in 'status_label_encoded' column:\", unique_status_labels)\n",
    "print(\"Number of unique values in 'Division_encoded' column:\", unique_divisions)\n",
    "print(\"Number of unique values in 'MajorGroup_encoded' column:\", unique_majorgroup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1abf0ae-6966-43bc-a652-7523ee634cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Division_encoded' column: [3 4 2 8 5 6 1 0 7 9]\n"
     ]
    }
   ],
   "source": [
    "unique_divisions = data['Division_encoded'].unique()\n",
    "print(\"Unique values in 'Division_encoded' column:\", unique_divisions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "381247f3-2cdf-4adf-b51a-e16ec84e1347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with missing values: 3993\n"
     ]
    }
   ],
   "source": [
    "missing_rows_count = data.isnull().any(axis=1).sum()\n",
    "print(\"Number of rows with missing values:\", missing_rows_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b98d5d1a-22e0-4ee6-8fc9-f156a2a97b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4978, 193)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete rows with missing values\n",
    "data_cleaned = data.dropna()\n",
    "# Delete non-numeric columns that are not encoded\n",
    "# Delete specified column\n",
    "data_cleaned = data_cleaned.drop(['company_name', 'status_label', 'Division', 'MajorGroup', 'last_year', 'company_name_encoded'], axis=1)\n",
    "\n",
    "data_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22f1ba13-272c-4957-96db-dd37c4602510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       X1_last1year  X1_last2year  X1_last3year  X1_last4year  X1_last5year  \\\n",
       "0           942.70        888.50       873.100         954.1      1116.900   \n",
       "1          1107.70        900.20      1077.400        1008.2       942.700   \n",
       "3        581502.00     353541.00   1037047.000      672072.0       692.991   \n",
       "5          6838.00       6642.00      5935.000        7229.0      6902.000   \n",
       "6        160865.00     173942.00    212978.000      228456.0    142967.000   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "8959       8218.00         21.33     16699.000       18523.0     16814.000   \n",
       "8963        362.33     310358.00    405282.000      359824.0    331465.000   \n",
       "8965      22026.00      26515.00        13.256        1801.0      5941.000   \n",
       "8966      10566.00      11738.00      9599.000        9789.0     11645.000   \n",
       "8969        931.60       1032.70       829.300         735.1       973.800   \n",
       "\n",
       "      X2_last1year  X2_last2year  X2_last3year  X2_last4year  X2_last5year  \\\n",
       "0           1524.7      1504.100      1442.100        1515.0      2199.500   \n",
       "1           1474.5      1343.600      1921.000        1764.8      1611.400   \n",
       "3        1288165.0    927239.000      1623.383     2003842.0   2329268.000   \n",
       "5          25088.0     25438.000     25175.000       28571.0     29145.000   \n",
       "6         392582.0    438549.000    498634.000      598819.0    414365.000   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "8959       10814.0        24.830     25102.000       28339.0     28369.000   \n",
       "8963      471155.0       425.563    529043.000      489109.0       461.488   \n",
       "8965       28813.0     36646.000     19899.000       16574.0     23139.000   \n",
       "8966       28278.0     26206.000     23442.000       22757.0     24283.000   \n",
       "8969        2810.2      2542.000      2247.400        2285.3      2015.900   \n",
       "\n",
       "      ...  nyse_last4year  nyse_last5year  nasdaq_last1year  nasdaq_last2year  \\\n",
       "0     ...    10699.956624     9467.185872       6293.024211       5015.926717   \n",
       "1     ...     9685.001790     8434.441610       2333.908345       1856.529999   \n",
       "3     ...     6645.525065     5478.855835       2587.587504       2278.996664   \n",
       "5     ...     9685.001790     8434.441610       2333.908345       1856.529999   \n",
       "6     ...    10606.906738    10699.956624       7405.502482       6293.024211   \n",
       "...   ...             ...             ...               ...               ...   \n",
       "8959  ...    10699.956624     9467.185872       6293.024211       5015.926717   \n",
       "8963  ...    10606.906738    10699.956624       7405.502482       6293.024211   \n",
       "8965  ...    10606.906738    10699.956624       7405.502482       6293.024211   \n",
       "8966  ...    10606.906738    10699.956624       7405.502482       6293.024211   \n",
       "8969  ...    10606.906738    10699.956624       7405.502482       6293.024211   \n",
       "\n",
       "      nasdaq_last3year  nasdaq_last4year  nasdaq_last5year  Division_encoded  \\\n",
       "0          4932.729126       4414.850057       3575.141642                 3   \n",
       "1          2148.948334       2587.587504       2278.996664                 3   \n",
       "3          2100.603343       1992.867482       1659.239176                 3   \n",
       "5          2148.948334       2587.587504       2278.996664                 4   \n",
       "6          5015.926717       4932.729126       4414.850057                 3   \n",
       "...                ...               ...               ...               ...   \n",
       "8959       4932.729126       4414.850057       3575.141642                 3   \n",
       "8963       5015.926717       4932.729126       4414.850057                 3   \n",
       "8965       5015.926717       4932.729126       4414.850057                 3   \n",
       "8966       5015.926717       4932.729126       4414.850057                 3   \n",
       "8969       5015.926717       4932.729126       4414.850057                 8   \n",
       "\n",
       "      MajorGroup_encoded  status_label_encoded  \n",
       "0                     29                     0  \n",
       "1                     28                     0  \n",
       "3                     20                     0  \n",
       "5                     36                     1  \n",
       "6                     27                     0  \n",
       "...                  ...                   ...  \n",
       "8959                  27                     0  \n",
       "8963                  20                     0  \n",
       "8965                  28                     0  \n",
       "8966                  20                     0  \n",
       "8969                  60                     0  \n",
       "\n",
       "[4978 rows x 193 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89dd5f1e-dc82-4769-b937-5bb68e3d9f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4548\n",
      "1     430\n",
      "Name: status_label_encoded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "status_counts = data_cleaned['status_label_encoded'].value_counts()\n",
    "print(status_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a330463-b2f8-4aa1-85a6-f2ad40621a69",
   "metadata": {},
   "source": [
    "### 1. RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f159c74-a2f6-46b8-b156-d9db13dd3a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the impact of imbalanced datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317d5616-60a7-4288-b8a2-6630bd5fbe7d",
   "metadata": {},
   "source": [
    "#### 1.1 imbalance dataset + CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90fff82c-02bc-4660-86fb-87d2b8ed60f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9076305220883534\n",
      "Cross-validation Scores: [0.91969887 0.92220828 0.91708543 0.92211055 0.92085427]\n",
      "Mean CV Accuracy: 0.9203914806151208\n",
      "Test Accuracy: 0.9046184738955824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data_cleaned.drop('status_label_encoded', axis=1)\n",
    "y = data_cleaned['status_label_encoded']\n",
    "\n",
    "# Split the data set into training set, validation set and test set\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 80% training, 20% validation\n",
    "\n",
    "# Define a random forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# Train the model on the training set\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_predictions = rf_classifier.predict(X_val)\n",
    "# Calculate accuracy on validation set\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Perform cross-validation on the training set\n",
    "cv_scores = cross_val_score(rf_classifier, X_train_val, y_train_val, cv=5)\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())\n",
    "# Retrain the model on the entire training set\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = rf_classifier.predict(X_test)\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef9d866c-bd00-40bf-9b07-b63d8c2b2bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9046184738955824\n",
      "Precision: 1.0\n",
      "Recall: 0.020618556701030927\n",
      "F1 Score: 0.04040404040404041\n",
      "Micro F1 Score: 0.9046184738955824\n",
      "Macro F1 Score: 0.49510957434887704\n",
      "ROC AUC: 0.8492311044344805\n",
      "Confusion Matrix:\n",
      "[[899   0]\n",
      " [ 95   2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, roc_curve, confusion_matrix\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculation precision\n",
    "precision = precision_score(y_test, test_predictions)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, test_predictions)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "y_prob = rf_classifier.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2ca22-1117-4c1e-bebc-db9b174d16be",
   "metadata": {},
   "source": [
    "#### 1.2 SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fbcd72-d620-4567-92ec-670b1b3319ac",
   "metadata": {},
   "source": [
    "##### 1.2.1 SMOTE + cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "728e436f-44d3-46fd-9903-b2c9f1f19de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2747\n",
      "1    2747\n",
      "Name: status_label_encoded, dtype: int64\n",
      "Validation Accuracy: 0.9076305220883534\n",
      "Cross-validation Scores: [0.92372881 0.98459168 0.98228043 0.98844376 0.93066256]\n",
      "Mean CV Accuracy: 0.9619414483821263\n",
      "Test Accuracy: 0.9066265060240963\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data_cleaned.drop('status_label_encoded', axis=1)\n",
    "y = data_cleaned['status_label_encoded']\n",
    "\n",
    "# Split the data into training + validation and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Further split the training + validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Apply SMOTE only on the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print the number of samples after oversampling\n",
    "print(pd.Series(y_train_resampled).value_counts())\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define a random forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# Train the model on the training set\n",
    "rf_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_predictions = rf_classifier.predict(X_val)\n",
    "# Calculate accuracy on validation set\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Combine resampled training set and validation set\n",
    "X_train_val_reshape = pd.concat([pd.DataFrame(X_train_resampled), pd.DataFrame(X_val)], axis=0)\n",
    "y_train_val_reshape = pd.concat([pd.Series(y_train_resampled), pd.Series(y_val)], axis=0)\n",
    "\n",
    "\n",
    "# Perform cross-validation on the train_val set\n",
    "cv_scores = cross_val_score(rf_classifier, X_train_val_reshape, y_train_val_reshape, cv=5)\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())\n",
    "# Retrain the model on the train_val set\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = rf_classifier.predict(X_test)\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e483ae23-d2a2-4585-bf4b-a4a62e6d5fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9066265060240963\n",
      "Precision: 0.5714285714285714\n",
      "Recall: 0.16494845360824742\n",
      "F1 Score: 0.256\n",
      "Micro F1 Score: 0.9066265060240963\n",
      "Macro F1 Score: 0.6030937332619175\n",
      "ROC AUC: 0.8306652294072452\n",
      "Confusion Matrix:\n",
      "[[887  12]\n",
      " [ 81  16]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, roc_curve, confusion_matrix\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, test_predictions)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, test_predictions)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "y_prob = rf_classifier.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f701d5f-c473-4ad0-91f1-33a87ee76802",
   "metadata": {},
   "source": [
    "##### 1.2.2 SMOTE + CV + FS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e8954c-8861-4ab4-9195-8e51739822e4",
   "metadata": {},
   "source": [
    "##### 1.2.3 SMOTE + GRID + FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e005918e-9f5a-4fbe-a1c2-57b3de3bf4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "Index(['X1_last3year', 'X3_last3year', 'X3_last4year', 'X3_last5year',\n",
      "       'X4_last1year', 'X4_last2year', 'X4_last3year', 'X4_last4year',\n",
      "       'X4_last5year', 'X5_last3year', 'X5_last5year', 'X6_last1year',\n",
      "       'X6_last2year', 'X7_last1year', 'X9_last1year', 'X9_last2year',\n",
      "       'X9_last3year', 'X9_last4year', 'X9_last5year', 'X10_last1year',\n",
      "       'X10_last2year', 'X10_last3year', 'X10_last5year', 'X11_last1year',\n",
      "       'X11_last2year', 'X11_last3year', 'X11_last4year', 'X11_last5year',\n",
      "       'X12_last1year', 'X12_last2year', 'X12_last3year', 'X12_last4year',\n",
      "       'X13_last3year', 'X13_last4year', 'X15_last1year', 'X16_last2year',\n",
      "       'X16_last3year', 'X16_last4year', 'X18_last2year', 'X18_last3year',\n",
      "       'X18_last4year', 'X1_last2year_ycr', 'X1_last3year_ycr',\n",
      "       'X1_last4year_ycr', 'X1_last5year_ycr', 'X2_last1year_ycr',\n",
      "       'X2_last5year_ycr', 'X3_last1year_ycr', 'X4_last2year_ycr',\n",
      "       'X4_last3year_ycr', 'X5_last2year_ycr', 'X5_last3year_ycr',\n",
      "       'X5_last4year_ycr', 'X5_last5year_ycr', 'X6_last1year_ycr',\n",
      "       'X6_last3year_ycr', 'X6_last5year_ycr', 'X8_last2year_ycr',\n",
      "       'X8_last3year_ycr', 'X9_last1year_ycr', 'X9_last2year_ycr',\n",
      "       'X9_last3year_ycr', 'X9_last4year_ycr', 'X9_last5year_ycr',\n",
      "       'X10_last1year_ycr', 'X10_last2year_ycr', 'X10_last3year_ycr',\n",
      "       'X11_last1year_ycr', 'X11_last3year_ycr', 'X12_last1year_ycr',\n",
      "       'X12_last4year_ycr', 'X13_last1year_ycr', 'X13_last2year_ycr',\n",
      "       'X13_last3year_ycr', 'X13_last4year_ycr', 'X13_last5year_ycr',\n",
      "       'X15_last1year_ycr', 'X15_last2year_ycr', 'X15_last4year_ycr',\n",
      "       'X16_last3year_ycr', 'X16_last4year_ycr', 'X18_last2year_ycr',\n",
      "       'X18_last3year_ycr', 'X18_last4year_ycr', 'nyse_last1year',\n",
      "       'nyse_last2year', 'nyse_last3year', 'nyse_last4year', 'nyse_last5year',\n",
      "       'nasdaq_last1year', 'nasdaq_last2year', 'nasdaq_last3year',\n",
      "       'nasdaq_last4year', 'nasdaq_last5year', 'Division_encoded',\n",
      "       'MajorGroup_encoded'],\n",
      "      dtype='object')\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Best Score: 0.9679692252105324\n",
      "Validation Accuracy with Best Model: 0.9036144578313253\n",
      "Test Accuracy with Best Model: 0.9076305220883534\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data_cleaned.drop('status_label_encoded', axis=1)\n",
    "y = data_cleaned['status_label_encoded']\n",
    "\n",
    "# Split the data into training + validation and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Further split the training + validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Apply SMOTE only on the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define a random forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Use SelectFromModel for feature selection\n",
    "selector = SelectFromModel(estimator=rf_classifier, threshold='median')  #better precision, worse recall&f1, compare with mean\n",
    "X_train_resampled_selected = selector.fit_transform(X_train_resampled, y_train_resampled)\n",
    "selected_features = X_train_resampled.columns[selector.get_support()]   #Select a list of column names for the characteristics.\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_resampled_selected, y_train_resampled)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Get the best model\n",
    "best_rf_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the validation set with selected features\n",
    "X_val_selected = selector.transform(X_val)\n",
    "val_predictions = best_rf_classifier.predict(X_val_selected)\n",
    "# Calculate accuracy on validation set\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(\"Validation Accuracy with Best Model:\", val_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions on the test set with the best model\n",
    "X_test_selected = selector.transform(X_test)\n",
    "test_predictions = best_rf_classifier.predict(X_test_selected)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy with Best Model:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0e87ddb-5dd8-44d4-a086-1c8eff459c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9076305220883534\n",
      "Precision: 0.5714285714285714\n",
      "Recall: 0.20618556701030927\n",
      "F1 Score: 0.30303030303030304\n",
      "Micro F1 Score: 0.9076305220883534\n",
      "Macro F1 Score: 0.6267839687194526\n",
      "ROC AUC: 0.8447186450007454\n",
      "Confusion Matrix:\n",
      "[[884  15]\n",
      " [ 77  20]]\n"
     ]
    }
   ],
   "source": [
    "#The evaluation metrics on the test set are calculated directly without threshold selection and re-prediction.\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, roc_curve, confusion_matrix\n",
    "\n",
    "#Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, test_predictions)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, test_predictions)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "y_prob = best_rf_classifier.predict_proba(X_test_selected)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc679609-6dab-41cc-91a5-9dd2a1dde22c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.3 processing imbalanced dataset, Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27b3b807-7807-42db-bdcf-0d82c53d4a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersampling +grid +fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a76a68fa-dc0d-4cb3-8d15-dc35763e04b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "Index(['X1_last4year', 'X1_last5year', 'X3_last2year', 'X3_last3year',\n",
      "       'X3_last4year', 'X4_last1year', 'X4_last2year', 'X4_last3year',\n",
      "       'X4_last5year', 'X5_last3year', 'X6_last1year', 'X6_last4year',\n",
      "       'X7_last1year', 'X8_last2year', 'X8_last4year', 'X9_last2year',\n",
      "       'X9_last3year', 'X10_last5year', 'X11_last1year', 'X11_last2year',\n",
      "       'X11_last3year', 'X11_last4year', 'X11_last5year', 'X12_last1year',\n",
      "       'X12_last2year', 'X12_last3year', 'X12_last4year', 'X13_last1year',\n",
      "       'X13_last3year', 'X13_last4year', 'X15_last1year', 'X15_last2year',\n",
      "       'X15_last3year', 'X18_last1year', 'X18_last2year', 'X18_last4year',\n",
      "       'X1_last1year_ycr', 'X1_last2year_ycr', 'X1_last3year_ycr',\n",
      "       'X1_last4year_ycr', 'X1_last5year_ycr', 'X2_last1year_ycr',\n",
      "       'X2_last3year_ycr', 'X2_last4year_ycr', 'X3_last2year_ycr',\n",
      "       'X4_last1year_ycr', 'X5_last2year_ycr', 'X5_last3year_ycr',\n",
      "       'X5_last4year_ycr', 'X6_last1year_ycr', 'X6_last3year_ycr',\n",
      "       'X6_last4year_ycr', 'X7_last2year_ycr', 'X8_last2year_ycr',\n",
      "       'X8_last4year_ycr', 'X8_last5year_ycr', 'X9_last1year_ycr',\n",
      "       'X9_last2year_ycr', 'X9_last3year_ycr', 'X9_last5year_ycr',\n",
      "       'X10_last3year_ycr', 'X10_last4year_ycr', 'X11_last1year_ycr',\n",
      "       'X11_last2year_ycr', 'X11_last4year_ycr', 'X11_last5year_ycr',\n",
      "       'X12_last2year_ycr', 'X12_last4year_ycr', 'X13_last1year_ycr',\n",
      "       'X13_last4year_ycr', 'X13_last5year_ycr', 'X14_last2year_ycr',\n",
      "       'X14_last4year_ycr', 'X15_last1year_ycr', 'X15_last2year_ycr',\n",
      "       'X15_last3year_ycr', 'X15_last4year_ycr', 'X15_last5year_ycr',\n",
      "       'X16_last1year_ycr', 'X16_last4year_ycr', 'X17_last3year_ycr',\n",
      "       'X18_last2year_ycr', 'X18_last3year_ycr', 'X18_last4year_ycr',\n",
      "       'nyse_last1year', 'nyse_last2year', 'nyse_last3year', 'nyse_last4year',\n",
      "       'nyse_last5year', 'nasdaq_last1year', 'nasdaq_last2year',\n",
      "       'nasdaq_last3year', 'nasdaq_last4year', 'nasdaq_last5year',\n",
      "       'Division_encoded', 'MajorGroup_encoded'],\n",
      "      dtype='object')\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best Score: 0.7804824561403509\n",
      "Validation Accuracy with Best Model: 0.7841365461847389\n",
      "Test Accuracy with Best Model: 0.7670682730923695\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data_cleaned.drop('status_label_encoded', axis=1)\n",
    "y = data_cleaned['status_label_encoded']\n",
    "\n",
    "# Split the data into training + validation and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Further split the training + validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define an undersampler\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define a random forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Use SelectFromModel for feature selection\n",
    "selector = SelectFromModel(estimator=rf_classifier, threshold='median')  #better precision, worse recall&f1, compare with mean\n",
    "X_train_resampled_selected = selector.fit_transform(X_train_resampled, y_train_resampled)\n",
    "selected_features = X_train_resampled.columns[selector.get_support()]   #Select a list of column names for the characteristics.\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_resampled_selected, y_train_resampled)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Get the best model\n",
    "best_rf_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the validation set with selected features\n",
    "X_val_selected = selector.transform(X_val)\n",
    "val_predictions = best_rf_classifier.predict(X_val_selected)\n",
    "# Calculate accuracy on validation set\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(\"Validation Accuracy with Best Model:\", val_accuracy)\n",
    "\n",
    "\n",
    "# Make predictions on the test set with the best model\n",
    "X_test_selected = selector.transform(X_test)\n",
    "test_predictions = best_rf_classifier.predict(X_test_selected)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy with Best Model:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38929a15-8dea-4b96-a6e9-00dac2aa4eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7670682730923695\n",
      "Precision: 0.26804123711340205\n",
      "Recall: 0.8041237113402062\n",
      "F1 Score: 0.4020618556701031\n",
      "Micro F1 Score: 0.7670682730923695\n",
      "Macro F1 Score: 0.6287117258400391\n",
      "ROC AUC: 0.8441624714746052\n",
      "Confusion Matrix:\n",
      "[[686 213]\n",
      " [ 19  78]]\n"
     ]
    }
   ],
   "source": [
    "#The evaluation metrics on the test set are calculated directly without threshold selection and re-prediction.\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, roc_curve, confusion_matrix\n",
    "\n",
    "#Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, test_predictions)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, test_predictions)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "y_prob = best_rf_classifier.predict_proba(X_test_selected)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9228af36-d91a-44b9-ba3c-a77f93a903ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80fd8821-7338-45dc-a3e0-949fefa793bc",
   "metadata": {},
   "source": [
    "### 2. XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca37366c-2d39-4c57-9288-5724a2d0fe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1 SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96464bb3-c663-4853-bdf8-b2a44daa0974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2747\n",
      "1    2747\n",
      "Name: status_label_encoded, dtype: int64\n",
      "[0]\ttrain-logloss:0.63392\teval-logloss:0.64883\n",
      "[1]\ttrain-logloss:0.58283\teval-logloss:0.61033\n",
      "[2]\ttrain-logloss:0.53739\teval-logloss:0.57775\n",
      "[3]\ttrain-logloss:0.49657\teval-logloss:0.54928\n",
      "[4]\ttrain-logloss:0.45999\teval-logloss:0.52286\n",
      "[5]\ttrain-logloss:0.42704\teval-logloss:0.49926\n",
      "[6]\ttrain-logloss:0.39665\teval-logloss:0.47686\n",
      "[7]\ttrain-logloss:0.36937\teval-logloss:0.45837\n",
      "[8]\ttrain-logloss:0.34414\teval-logloss:0.44103\n",
      "[9]\ttrain-logloss:0.32140\teval-logloss:0.42586\n",
      "[10]\ttrain-logloss:0.30027\teval-logloss:0.41063\n",
      "[11]\ttrain-logloss:0.28114\teval-logloss:0.39761\n",
      "[12]\ttrain-logloss:0.26349\teval-logloss:0.38446\n",
      "[13]\ttrain-logloss:0.24687\teval-logloss:0.37368\n",
      "[14]\ttrain-logloss:0.23180\teval-logloss:0.36414\n",
      "[15]\ttrain-logloss:0.21758\teval-logloss:0.35438\n",
      "[16]\ttrain-logloss:0.20463\teval-logloss:0.34600\n",
      "[17]\ttrain-logloss:0.19276\teval-logloss:0.33837\n",
      "[18]\ttrain-logloss:0.18150\teval-logloss:0.33127\n",
      "[19]\ttrain-logloss:0.17130\teval-logloss:0.32525\n",
      "[20]\ttrain-logloss:0.16157\teval-logloss:0.31896\n",
      "[21]\ttrain-logloss:0.15258\teval-logloss:0.31270\n",
      "[22]\ttrain-logloss:0.14427\teval-logloss:0.30795\n",
      "[23]\ttrain-logloss:0.13652\teval-logloss:0.30332\n",
      "[24]\ttrain-logloss:0.12928\teval-logloss:0.29940\n",
      "[25]\ttrain-logloss:0.12252\teval-logloss:0.29503\n",
      "[26]\ttrain-logloss:0.11619\teval-logloss:0.29190\n",
      "[27]\ttrain-logloss:0.11010\teval-logloss:0.28782\n",
      "[28]\ttrain-logloss:0.10454\teval-logloss:0.28426\n",
      "[29]\ttrain-logloss:0.09938\teval-logloss:0.28115\n",
      "[30]\ttrain-logloss:0.09450\teval-logloss:0.27709\n",
      "[31]\ttrain-logloss:0.09001\teval-logloss:0.27452\n",
      "[32]\ttrain-logloss:0.08566\teval-logloss:0.27194\n",
      "[33]\ttrain-logloss:0.08170\teval-logloss:0.26976\n",
      "[34]\ttrain-logloss:0.07787\teval-logloss:0.26731\n",
      "[35]\ttrain-logloss:0.07435\teval-logloss:0.26551\n",
      "[36]\ttrain-logloss:0.07098\teval-logloss:0.26432\n",
      "[37]\ttrain-logloss:0.06790\teval-logloss:0.26315\n",
      "[38]\ttrain-logloss:0.06501\teval-logloss:0.26164\n",
      "[39]\ttrain-logloss:0.06219\teval-logloss:0.25940\n",
      "[40]\ttrain-logloss:0.05963\teval-logloss:0.25786\n",
      "[41]\ttrain-logloss:0.05714\teval-logloss:0.25711\n",
      "[42]\ttrain-logloss:0.05470\teval-logloss:0.25620\n",
      "[43]\ttrain-logloss:0.05253\teval-logloss:0.25536\n",
      "[44]\ttrain-logloss:0.05047\teval-logloss:0.25431\n",
      "[45]\ttrain-logloss:0.04860\teval-logloss:0.25362\n",
      "[46]\ttrain-logloss:0.04668\teval-logloss:0.25301\n",
      "[47]\ttrain-logloss:0.04487\teval-logloss:0.25208\n",
      "[48]\ttrain-logloss:0.04311\teval-logloss:0.25180\n",
      "[49]\ttrain-logloss:0.04150\teval-logloss:0.25159\n",
      "[50]\ttrain-logloss:0.04000\teval-logloss:0.25038\n",
      "[51]\ttrain-logloss:0.03850\teval-logloss:0.24979\n",
      "[52]\ttrain-logloss:0.03717\teval-logloss:0.24919\n",
      "[53]\ttrain-logloss:0.03589\teval-logloss:0.24913\n",
      "[54]\ttrain-logloss:0.03463\teval-logloss:0.24883\n",
      "[55]\ttrain-logloss:0.03346\teval-logloss:0.24883\n",
      "[56]\ttrain-logloss:0.03229\teval-logloss:0.24882\n",
      "[57]\ttrain-logloss:0.03125\teval-logloss:0.24898\n",
      "[58]\ttrain-logloss:0.03025\teval-logloss:0.24869\n",
      "[59]\ttrain-logloss:0.02928\teval-logloss:0.24793\n",
      "[60]\ttrain-logloss:0.02833\teval-logloss:0.24851\n",
      "[61]\ttrain-logloss:0.02749\teval-logloss:0.24860\n",
      "[62]\ttrain-logloss:0.02663\teval-logloss:0.24865\n",
      "[63]\ttrain-logloss:0.02585\teval-logloss:0.24825\n",
      "[64]\ttrain-logloss:0.02509\teval-logloss:0.24797\n",
      "[65]\ttrain-logloss:0.02431\teval-logloss:0.24819\n",
      "[66]\ttrain-logloss:0.02361\teval-logloss:0.24799\n",
      "[67]\ttrain-logloss:0.02294\teval-logloss:0.24714\n",
      "[68]\ttrain-logloss:0.02229\teval-logloss:0.24721\n",
      "[69]\ttrain-logloss:0.02170\teval-logloss:0.24774\n",
      "[70]\ttrain-logloss:0.02112\teval-logloss:0.24789\n",
      "[71]\ttrain-logloss:0.02060\teval-logloss:0.24825\n",
      "[72]\ttrain-logloss:0.02009\teval-logloss:0.24784\n",
      "[73]\ttrain-logloss:0.01956\teval-logloss:0.24748\n",
      "[74]\ttrain-logloss:0.01906\teval-logloss:0.24819\n",
      "[75]\ttrain-logloss:0.01859\teval-logloss:0.24799\n",
      "[76]\ttrain-logloss:0.01810\teval-logloss:0.24934\n",
      "[77]\ttrain-logloss:0.01768\teval-logloss:0.24899\n",
      "Test Accuracy: 0.8995983935742972\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data_cleaned.drop('status_label_encoded', axis=1)\n",
    "y = data_cleaned['status_label_encoded']\n",
    "\n",
    "# Split the data into training + validation and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Further split the training + validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Apply SMOTE only on the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "# Print the number of samples after oversampling\n",
    "print(pd.Series(y_train_resampled).value_counts())\n",
    "\n",
    "# Convert data to DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train_resampled, label=y_train_resampled)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # Binary classification\n",
    "    'eval_metric': 'logloss',         # Logarithmic loss\n",
    "    'eta': 0.07,                       # Learning rate\n",
    "    'max_depth': 60,                   # Maximum depth of the tree\n",
    "    'subsample': 0.9,                 # Subsample ratio of the training instances\n",
    "    'colsample_bytree': 0.9,          # Subsample ratio of columns when constructing each tree\n",
    "    'lambda': 1,                      # L2 regularization term (default is 1)\n",
    "    'alpha': 0,                       # L1 regularization term (default is 0)\n",
    "    #'num_rounds': 100,                # Number of boosting rounds\n",
    "    'seed': 42                        # Random seed\n",
    "}\n",
    "\n",
    "# Train XGBoost model\n",
    "num_rounds = 100\n",
    "watchlist = [(dtrain, 'train'), (dval, 'eval')]\n",
    "xgb_model = xgb.train(params, dtrain, num_rounds, evals=watchlist, early_stopping_rounds=10)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions_proba = xgb_model.predict(dtest)\n",
    "test_predictions = [1 if x > 0.5 else 0 for x in test_predictions_proba]\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8edcafa2-733b-405e-901d-f1b596e3e118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8995983935742972\n",
      "Precision: 0.46511627906976744\n",
      "Recall: 0.20618556701030927\n",
      "F1 Score: 0.2857142857142857\n",
      "Micro F1 Score: 0.8995983935742972\n",
      "Macro F1 Score: 0.6158593026843566\n",
      "ROC AUC: 0.8464273018130108\n",
      "Confusion Matrix:\n",
      "[[876  23]\n",
      " [ 77  20]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, test_predictions)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, test_predictions)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, test_predictions_proba)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "775f5465-3caa-4d00-908a-bdff4eecaab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 SMOTE + FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b2d1469-e2c3-4039-b7cb-448d7139d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 SMOTE + FS + GRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ece5d910-f089-45fd-aa80-8e42381984d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "Index(['X3_last3year', 'X3_last4year', 'X4_last2year', 'X4_last4year',\n",
      "       'X6_last1year', 'X8_last3year', 'X9_last2year', 'X9_last4year',\n",
      "       'X10_last5year', 'X11_last1year', 'X11_last2year', 'X12_last1year',\n",
      "       'X12_last3year', 'X16_last2year', 'X16_last4year', 'X2_last2year_ycr',\n",
      "       'X4_last3year_ycr', 'X5_last3year_ycr', 'X6_last2year_ycr',\n",
      "       'X7_last1year_ycr', 'X7_last5year_ycr', 'X8_last2year_ycr',\n",
      "       'X9_last3year_ycr', 'X9_last4year_ycr', 'X10_last2year_ycr',\n",
      "       'X10_last3year_ycr', 'X13_last1year_ycr', 'X13_last3year_ycr',\n",
      "       'X15_last1year_ycr', 'nyse_last1year', 'nyse_last3year',\n",
      "       'nyse_last4year', 'nyse_last5year', 'nasdaq_last4year',\n",
      "       'Division_encoded'],\n",
      "      dtype='object')\n",
      "Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 25, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.9}\n",
      "Best Score: 0.9632325130811088\n",
      "Val Accuracy: 0.9036144578313253\n",
      "Test Accuracy: 0.9136546184738956\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data_cleaned.drop('status_label_encoded', axis=1)\n",
    "y = data_cleaned['status_label_encoded']\n",
    "\n",
    "# Split the data into training + validation and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training + validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Apply SMOTE only on the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define a XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# Perform feature selection \n",
    "selector = SelectFromModel(estimator=xgb_classifier, threshold='mean')  # threshold: mean\n",
    "selector.fit(X_train_resampled, y_train_resampled)\n",
    "selected_features = X_train_resampled.columns[selector.get_support()]\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)\n",
    "\n",
    "# Transform the datasets\n",
    "X_train_selected = selector.transform(X_train_resampled)\n",
    "X_val_selected = selector.transform(X_val)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [5, 25, 70],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0], \n",
    "}\n",
    "\n",
    "# Create cross-validation folds\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV to data\n",
    "grid_search.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Print best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Train XGBoost model with best parameters\n",
    "best_params = grid_search.best_params_\n",
    "best_xgb_classifier = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_predictions = best_xgb_classifier.predict(X_val_selected)\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(\"Val Accuracy:\", val_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = best_xgb_classifier.predict(X_test_selected)\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18809830-0339-4e21-b287-05dfccb9671d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9136546184738956\n",
      "Precision: 0.6\n",
      "Recall: 0.3402061855670103\n",
      "F1 Score: 0.4342105263157895\n",
      "Micro F1 Score: 0.9136546184738956\n",
      "Macro F1 Score: 0.6937356979405035\n",
      "ROC AUC: 0.8486749309083402\n",
      "Confusion Matrix:\n",
      "[[877  22]\n",
      " [ 64  33]]\n"
     ]
    }
   ],
   "source": [
    "#The evaluation metrics on the test set are calculated directly without threshold selection and re-prediction.\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, roc_curve, confusion_matrix\n",
    "\n",
    "#Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, test_predictions)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, test_predictions)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "y_prob = best_xgb_classifier.predict_proba(X_test_selected)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9289b3b2-5aec-457f-ac51-538933822c65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#2.4 UNDERSAMPLING + FS +GRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b185805-44a9-42d4-83ed-29607e53d89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "Index(['X1_last2year', 'X1_last3year', 'X1_last5year', 'X2_last1year',\n",
      "       'X2_last2year', 'X2_last4year', 'X2_last5year', 'X3_last3year',\n",
      "       'X3_last5year', 'X4_last2year', 'X4_last3year', 'X5_last1year',\n",
      "       'X5_last3year', 'X6_last3year', 'X8_last3year', 'X8_last5year',\n",
      "       'X9_last2year', 'X10_last5year', 'X11_last1year', 'X11_last5year',\n",
      "       'X12_last2year', 'X13_last3year', 'X14_last1year', 'X14_last2year',\n",
      "       'X15_last1year', 'X15_last3year', 'X16_last4year', 'X18_last1year',\n",
      "       'X1_last1year_ycr', 'X1_last2year_ycr', 'X3_last2year_ycr',\n",
      "       'X4_last3year_ycr', 'X4_last4year_ycr', 'X4_last5year_ycr',\n",
      "       'X5_last1year_ycr', 'X5_last2year_ycr', 'X5_last4year_ycr',\n",
      "       'X6_last1year_ycr', 'X6_last4year_ycr', 'X7_last1year_ycr',\n",
      "       'X7_last2year_ycr', 'X7_last3year_ycr', 'X8_last2year_ycr',\n",
      "       'X8_last3year_ycr', 'X8_last4year_ycr', 'X8_last5year_ycr',\n",
      "       'X9_last1year_ycr', 'X9_last3year_ycr', 'X9_last4year_ycr',\n",
      "       'X10_last4year_ycr', 'X10_last5year_ycr', 'X12_last3year_ycr',\n",
      "       'X12_last4year_ycr', 'X13_last3year_ycr', 'X13_last5year_ycr',\n",
      "       'X15_last1year_ycr', 'X15_last4year_ycr', 'X16_last1year_ycr',\n",
      "       'X16_last2year_ycr', 'nyse_last1year', 'nyse_last3year',\n",
      "       'nasdaq_last1year', 'MajorGroup_encoded'],\n",
      "      dtype='object')\n",
      "Best Parameters: {'colsample_bytree': 0.9, 'learning_rate': 1, 'max_depth': 25, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1.0}\n",
      "Best Score: 0.8031359649122807\n",
      "Val Accuracy: 0.7620481927710844\n",
      "Test Accuracy: 0.7710843373493976\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data_cleaned.drop('status_label_encoded', axis=1)\n",
    "y = data_cleaned['status_label_encoded']\n",
    "\n",
    "# Split the data into training + validation and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Further split the training + validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define an undersampler\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define a XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# Perform feature selection \n",
    "selector = SelectFromModel(estimator=xgb_classifier, threshold='mean')  # threshold: mean\n",
    "selector.fit(X_train_resampled, y_train_resampled)\n",
    "selected_features = X_train_resampled.columns[selector.get_support()]\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)\n",
    "\n",
    "# Transform the datasets\n",
    "X_train_selected = selector.transform(X_train_resampled)\n",
    "X_val_selected = selector.transform(X_val)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [5, 25, 70],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],     \n",
    "}\n",
    "\n",
    "# Create cross-validation folds\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV to data\n",
    "grid_search.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Print best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Train XGBoost model with best parameters\n",
    "best_params = grid_search.best_params_\n",
    "best_xgb_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_predictions = best_xgb_classifier.predict(X_val_selected)\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(\"Val Accuracy:\", val_accuracy)\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = best_xgb_classifier.predict(X_test_selected)\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5124c231-eaf4-474b-80c9-c3caaa427438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7710843373493976\n",
      "Precision: 0.2600732600732601\n",
      "Recall: 0.7319587628865979\n",
      "F1 Score: 0.38378378378378375\n",
      "Micro F1 Score: 0.7710843373493976\n",
      "Macro F1 Score: 0.6216082913986736\n",
      "ROC AUC: 0.8381477701455224\n",
      "Confusion Matrix:\n",
      "[[697 202]\n",
      " [ 26  71]]\n"
     ]
    }
   ],
   "source": [
    "#The evaluation metrics on the test set are calculated directly without threshold selection and re-prediction.\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, roc_curve, confusion_matrix\n",
    "\n",
    "#Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, test_predictions)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, test_predictions)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "y_prob = best_xgb_classifier.predict_proba(X_test_selected)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f705495-0cf3-4d0c-891d-ccd5586d0ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
