{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d162b6bb-04be-41c3-94af-44ab59e6500d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00c0043-c7ca-4492-ad2f-cced9d6fae30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2e3631-6704-4cac-8a49-88743235ff8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in 'company_name' column: 8971\n",
      "Number of unique values in 'status_label' column: 2\n",
      "Number of unique values in 'Division' column: 10\n",
      "Number of unique values in 'MajorGroup' column: 73\n",
      "Number of unique values in 'last_year' column: 20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data set\n",
    "data = pd.read_csv(\"new_df_selected3_last3years_adjusted.csv\")\n",
    "\n",
    "unique_company_names = data['company_name'].nunique()\n",
    "unique_status_labels = data['status_label'].nunique()\n",
    "unique_divisions = data['Division'].nunique()\n",
    "unique_majorgroup = data['MajorGroup'].nunique()\n",
    "unique_last_year = data['last_year'].nunique()\n",
    "\n",
    "print(\"Number of unique values in 'company_name' column:\", unique_company_names)\n",
    "print(\"Number of unique values in 'status_label' column:\", unique_status_labels)\n",
    "print(\"Number of unique values in 'Division' column:\", unique_divisions)\n",
    "print(\"Number of unique values in 'MajorGroup' column:\", unique_majorgroup)\n",
    "print(\"Number of unique values in 'last_year' column:\", unique_last_year)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263fa8e8-cf02-4f9e-a23d-74af29abb22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0552208d-295c-4128-90b8-ed6e4d3a1494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8971 entries, 0 to 8970\n",
      "Columns: 119 entries, company_name to nasdaq_last3year\n",
      "dtypes: float64(115), int64(1), object(3)\n",
      "memory usage: 8.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc4a5663-66c6-4f87-84bb-ff9ab875eba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  company_name status_label Division  MajorGroup  last_year  X1_last1year  \\\n",
      "0          C_1        alive        D          37     2017.0         942.7   \n",
      "1          C_2        alive        D          36     2010.0        1107.7   \n",
      "2          C_3        alive        D          38     2008.0       12686.0   \n",
      "3          C_4        alive        D          28     2007.0      581502.0   \n",
      "4          C_5        alive        D          35     1999.0       28957.0   \n",
      "\n",
      "   X1_last2year  X1_last3year  X2_last1year  X2_last2year  ...  \\\n",
      "0         888.5         873.1       1524.70        1504.1  ...   \n",
      "1         900.2        1077.4       1474.50        1343.6  ...   \n",
      "2       13454.0       13582.0      21401.00       27171.0  ...   \n",
      "3      353541.0     1037047.0    1288165.00      927239.0  ...   \n",
      "4           NaN           NaN         42.21           NaN  ...   \n",
      "\n",
      "   nyse_last1year  nyse_last2year  nyse_last3year  nasdaq_last1year  \\\n",
      "0    11912.848307    10451.377523    10606.906738       6293.024211   \n",
      "1     7166.229940     6100.795776     8001.502441       2333.908345   \n",
      "2     8001.502441     9685.001790     8434.441610       2148.948334   \n",
      "3     9685.001790     8434.441610     7364.758301       2587.587504   \n",
      "4     6549.827474             NaN             NaN       2787.559998   \n",
      "\n",
      "   nasdaq_last2year  nasdaq_last3year  company_name_encoded  Division_encoded  \\\n",
      "0       5015.926717       4932.729126                     0                 3   \n",
      "1       1856.529999       2148.948334                  1111                 3   \n",
      "2       2587.587504       2278.996664                  2222                 3   \n",
      "3       2278.996664       2100.603343                  3333                 3   \n",
      "4               NaN               NaN                  4444                 3   \n",
      "\n",
      "   MajorGroup_encoded  status_label_encoded  \n",
      "0                  29                     0  \n",
      "1                  28                     0  \n",
      "2                  30                     0  \n",
      "3                  20                     0  \n",
      "4                  27                     0  \n",
      "\n",
      "[5 rows x 123 columns]\n"
     ]
    }
   ],
   "source": [
    "# Encoding non-numeric columns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "# Label-encode the company_name column\n",
    "data['company_name_encoded'] = label_encoder.fit_transform(data['company_name'])\n",
    "\n",
    "\n",
    "# Label-encode the Division column\n",
    "data['Division_encoded'] = label_encoder.fit_transform(data['Division'])\n",
    "\n",
    "# Label-encode MajorGroup columns\n",
    "data['MajorGroup_encoded'] = label_encoder.fit_transform(data['MajorGroup'])\n",
    "#When using label encoding for feature encoding, the sequential relationship between categories will not be introduced and will not have an impact on prediction.\n",
    "\n",
    "# Encode the label of the status_label column\n",
    "data['status_label_encoded'] = label_encoder.fit_transform(data['status_label'])\n",
    "#With only two categories, it may be simpler and more appropriate to use label encoding as it maps the categories to 0 and 1, suitable for use in tree-based models. \n",
    "#If use one-hot encoding, a new column will be generated\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1f286d3-0047-4da4-90dc-dd63a2e84a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8971 entries, 0 to 8970\n",
      "Columns: 123 entries, company_name to status_label_encoded\n",
      "dtypes: float64(115), int32(3), int64(2), object(3)\n",
      "memory usage: 8.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "374fe89d-42d2-472f-8724-dcc6f06dff33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8971, 123)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b45588-522a-4d3c-8509-9749f7d3c4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in 'company_name_encoded' column: 8971\n",
      "Number of unique values in 'status_label_encoded' column: 2\n",
      "Number of unique values in 'Division_encoded' column: 10\n",
      "Number of unique values in 'MajorGroup_encoded' column: 73\n"
     ]
    }
   ],
   "source": [
    "unique_company_names = data['company_name_encoded'].nunique()\n",
    "unique_status_labels = data['status_label_encoded'].nunique()\n",
    "unique_divisions = data['Division_encoded'].nunique()\n",
    "unique_majorgroup = data['MajorGroup_encoded'].nunique()\n",
    "\n",
    "print(\"Number of unique values in 'company_name_encoded' column:\", unique_company_names)\n",
    "print(\"Number of unique values in 'status_label_encoded' column:\", unique_status_labels)\n",
    "print(\"Number of unique values in 'Division_encoded' column:\", unique_divisions)\n",
    "print(\"Number of unique values in 'MajorGroup_encoded' column:\", unique_majorgroup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1abf0ae-6966-43bc-a652-7523ee634cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Division_encoded' column: [3 4 2 8 5 6 1 0 7 9]\n"
     ]
    }
   ],
   "source": [
    "unique_divisions = data['Division_encoded'].unique()\n",
    "print(\"Unique values in 'Division_encoded' column:\", unique_divisions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "381247f3-2cdf-4adf-b51a-e16ec84e1347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with missing values: 2673\n"
     ]
    }
   ],
   "source": [
    "missing_rows_count = data.isnull().any(axis=1).sum()\n",
    "print(\"Number of rows with missing values:\", missing_rows_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b98d5d1a-22e0-4ee6-8fc9-f156a2a97b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6298, 117)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete rows with missing values\n",
    "data_cleaned = data.dropna()\n",
    "# Delete non-numeric columns that are not encoded\n",
    "# Delete specified column\n",
    "data_cleaned = data_cleaned.drop(['company_name', 'status_label', 'Division', 'MajorGroup', 'last_year', 'company_name_encoded'], axis=1)\n",
    "\n",
    "data_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22f1ba13-272c-4957-96db-dd37c4602510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       X1_last1year  X1_last2year  X1_last3year  X2_last1year  X2_last2year  \\\n",
       "0            942.7         888.5         873.1       1524.70       1504.10   \n",
       "1           1107.7         900.2        1077.4       1474.50       1343.60   \n",
       "2          12686.0       13454.0       13582.0      21401.00      27171.00   \n",
       "3         581502.0      353541.0     1037047.0    1288165.00     927239.00   \n",
       "5           6838.0        6642.0        5935.0      25088.00      25438.00   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "8966       10566.0       11738.0        9599.0      28278.00      26206.00   \n",
       "8967        3369.0        9049.0       21381.0       3466.00       9198.00   \n",
       "8968        2482.2        2340.6        2071.2       9401.50      10252.40   \n",
       "8969         931.6        1032.7         829.3       2810.20       2542.00   \n",
       "8970       82589.0      135207.0       63971.0       1625.37       1736.11   \n",
       "\n",
       "      X2_last3year  X3_last1year  X3_last2year  X3_last3year  X4_last1year  \\\n",
       "0         1442.100       1413.20      1422.700        1354.9         177.2   \n",
       "1         1921.000        677.20       600.500         870.7         650.8   \n",
       "2        14341.000      19334.00        17.589       15454.0          23.0   \n",
       "3         1623.383        267.81    229115.000      150257.0         300.0   \n",
       "5        25175.000      18138.00     16935.000       20232.0        9253.0   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "8966     23442.000      31288.00     26885.000       22127.0        8497.0   \n",
       "8967     21782.000        208.00      1077.000        4972.0           0.0   \n",
       "8968     10054.100        966.70      1833.200        1723.3        5350.7   \n",
       "8969      2247.400       1475.90      1269.600        1190.4        1409.5   \n",
       "8970   1746235.000      68817.00     66527.000       69074.0      632122.0   \n",
       "\n",
       "      ...  X18_last3year_ycr  nyse_last1year  nyse_last2year  nyse_last3year  \\\n",
       "0     ...           0.009996    11912.848307    10451.377523    10606.906738   \n",
       "1     ...           0.111583     7166.229940     6100.795776     8001.502441   \n",
       "2     ...           0.115936     8001.502441     9685.001790     8434.441610   \n",
       "3     ...          -0.670632     9685.001790     8434.441610     7364.758301   \n",
       "5     ...           0.117916     7166.229940     6100.795776     8001.502441   \n",
       "...   ...                ...             ...             ...             ...   \n",
       "8966  ...          -0.096823    12593.500651    11912.848307    10451.377523   \n",
       "8967  ...          -0.283315    11912.848307    10451.377523    10606.906738   \n",
       "8968  ...           0.418174    12593.500651    11912.848307    10451.377523   \n",
       "8969  ...           0.076355    12593.500651    11912.848307    10451.377523   \n",
       "8970  ...        1019.074141    12593.500651    11912.848307    10451.377523   \n",
       "\n",
       "      nasdaq_last1year  nasdaq_last2year  nasdaq_last3year  Division_encoded  \\\n",
       "0          6293.024211       5015.926717       4932.729126                 3   \n",
       "1          2333.908345       1856.529999       2148.948334                 3   \n",
       "2          2148.948334       2587.587504       2278.996664                 3   \n",
       "3          2587.587504       2278.996664       2100.603343                 3   \n",
       "5          2333.908345       1856.529999       2148.948334                 4   \n",
       "...                ...               ...               ...               ...   \n",
       "8966       7405.502482       6293.024211       5015.926717                 3   \n",
       "8967       6293.024211       5015.926717       4932.729126                 3   \n",
       "8968       7405.502482       6293.024211       5015.926717                 3   \n",
       "8969       7405.502482       6293.024211       5015.926717                 8   \n",
       "8970       7405.502482       6293.024211       5015.926717                 4   \n",
       "\n",
       "      MajorGroup_encoded  status_label_encoded  \n",
       "0                     29                     0  \n",
       "1                     28                     0  \n",
       "2                     30                     0  \n",
       "3                     20                     0  \n",
       "5                     36                     1  \n",
       "...                  ...                   ...  \n",
       "8966                  20                     0  \n",
       "8967                  30                     0  \n",
       "8968                  20                     0  \n",
       "8969                  60                     0  \n",
       "8970                  35                     0  \n",
       "\n",
       "[6298 rows x 117 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89dd5f1e-dc82-4769-b937-5bb68e3d9f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5784\n",
      "1     514\n",
      "Name: status_label_encoded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "status_counts = data_cleaned['status_label_encoded'].value_counts()\n",
    "print(status_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb4d796-4a39-485b-8be3-7e26de33edeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c069ed8-2c79-4097-88da-298688628eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ecdd909-ab93-4cb8-814b-c52442a692c5",
   "metadata": {},
   "source": [
    "### 2. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "007181c2-81ff-41d4-868e-f1f0db8955f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d876d174-b04b-4c66-ac73-81fe91c76d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.30063\teval-logloss:0.28198\n",
      "[1]\ttrain-logloss:0.28363\teval-logloss:0.27503\n",
      "[2]\ttrain-logloss:0.26813\teval-logloss:0.26965\n",
      "[3]\ttrain-logloss:0.25341\teval-logloss:0.26353\n",
      "[4]\ttrain-logloss:0.24007\teval-logloss:0.25761\n",
      "[5]\ttrain-logloss:0.22809\teval-logloss:0.25261\n",
      "[6]\ttrain-logloss:0.21697\teval-logloss:0.24839\n",
      "[7]\ttrain-logloss:0.20590\teval-logloss:0.24379\n",
      "[8]\ttrain-logloss:0.19573\teval-logloss:0.24034\n",
      "[9]\ttrain-logloss:0.18614\teval-logloss:0.23656\n",
      "[10]\ttrain-logloss:0.17759\teval-logloss:0.23374\n",
      "[11]\ttrain-logloss:0.16961\teval-logloss:0.23047\n",
      "[12]\ttrain-logloss:0.16210\teval-logloss:0.22758\n",
      "[13]\ttrain-logloss:0.15464\teval-logloss:0.22540\n",
      "[14]\ttrain-logloss:0.14782\teval-logloss:0.22245\n",
      "[15]\ttrain-logloss:0.14144\teval-logloss:0.22020\n",
      "[16]\ttrain-logloss:0.13543\teval-logloss:0.21812\n",
      "[17]\ttrain-logloss:0.12972\teval-logloss:0.21682\n",
      "[18]\ttrain-logloss:0.12409\teval-logloss:0.21481\n",
      "[19]\ttrain-logloss:0.11893\teval-logloss:0.21325\n",
      "[20]\ttrain-logloss:0.11408\teval-logloss:0.21276\n",
      "[21]\ttrain-logloss:0.10958\teval-logloss:0.21196\n",
      "[22]\ttrain-logloss:0.10552\teval-logloss:0.21068\n",
      "[23]\ttrain-logloss:0.10142\teval-logloss:0.20966\n",
      "[24]\ttrain-logloss:0.09744\teval-logloss:0.20877\n",
      "[25]\ttrain-logloss:0.09397\teval-logloss:0.20818\n",
      "[26]\ttrain-logloss:0.09062\teval-logloss:0.20684\n",
      "[27]\ttrain-logloss:0.08725\teval-logloss:0.20636\n",
      "[28]\ttrain-logloss:0.08395\teval-logloss:0.20573\n",
      "[29]\ttrain-logloss:0.08100\teval-logloss:0.20539\n",
      "[30]\ttrain-logloss:0.07821\teval-logloss:0.20439\n",
      "[31]\ttrain-logloss:0.07566\teval-logloss:0.20386\n",
      "[32]\ttrain-logloss:0.07311\teval-logloss:0.20286\n",
      "[33]\ttrain-logloss:0.07063\teval-logloss:0.20197\n",
      "[34]\ttrain-logloss:0.06825\teval-logloss:0.20174\n",
      "[35]\ttrain-logloss:0.06616\teval-logloss:0.20090\n",
      "[36]\ttrain-logloss:0.06405\teval-logloss:0.20031\n",
      "[37]\ttrain-logloss:0.06197\teval-logloss:0.19972\n",
      "[38]\ttrain-logloss:0.06007\teval-logloss:0.19910\n",
      "[39]\ttrain-logloss:0.05827\teval-logloss:0.19897\n",
      "[40]\ttrain-logloss:0.05661\teval-logloss:0.19914\n",
      "[41]\ttrain-logloss:0.05486\teval-logloss:0.19893\n",
      "[42]\ttrain-logloss:0.05320\teval-logloss:0.19875\n",
      "[43]\ttrain-logloss:0.05168\teval-logloss:0.19860\n",
      "[44]\ttrain-logloss:0.05019\teval-logloss:0.19858\n",
      "[45]\ttrain-logloss:0.04879\teval-logloss:0.19857\n",
      "[46]\ttrain-logloss:0.04747\teval-logloss:0.19907\n",
      "[47]\ttrain-logloss:0.04617\teval-logloss:0.19931\n",
      "[48]\ttrain-logloss:0.04493\teval-logloss:0.19917\n",
      "[49]\ttrain-logloss:0.04375\teval-logloss:0.19901\n",
      "[50]\ttrain-logloss:0.04257\teval-logloss:0.19917\n",
      "[51]\ttrain-logloss:0.04150\teval-logloss:0.19899\n",
      "[52]\ttrain-logloss:0.04043\teval-logloss:0.19940\n",
      "[53]\ttrain-logloss:0.03942\teval-logloss:0.19985\n",
      "[54]\ttrain-logloss:0.03849\teval-logloss:0.19992\n",
      "[55]\ttrain-logloss:0.03757\teval-logloss:0.19970\n",
      "Test Accuracy: 0.9293650793650794\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data_cleaned.drop('status_label_encoded', axis=1)\n",
    "y = data_cleaned['status_label_encoded']\n",
    "\n",
    "# Split the data into training + validation and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Further split the training + validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "# Convert data to DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # Binary classification\n",
    "    'eval_metric': 'logloss',         # Logarithmic loss\n",
    "    'eta': 0.07,                       # Learning rate\n",
    "    'max_depth': 60,                   # Maximum depth of the tree\n",
    "    'subsample': 0.9,                 # Subsample ratio of the training instances\n",
    "    'colsample_bytree': 0.9,          # Subsample ratio of columns when constructing each tree\n",
    "    'lambda': 1,                      # L2 regularization term (default is 1)\n",
    "    'alpha': 0,                       # L1 regularization term (default is 0)\n",
    "    'seed': 42                        # Random seed\n",
    "}\n",
    "\n",
    "# Train XGBoost model\n",
    "num_rounds = 100\n",
    "watchlist = [(dtrain, 'train'), (dval, 'eval')]\n",
    "xgb_model = xgb.train(params, dtrain, num_rounds, evals=watchlist, early_stopping_rounds=10)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions_proba = xgb_model.predict(dtest)\n",
    "test_predictions = [1 if x > 0.5 else 0 for x in test_predictions_proba]\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d67a182b-b814-4f7f-82a0-b944e77a478a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9293650793650794\n",
      "Precision: 0.8\n",
      "Recall: 0.12244897959183673\n",
      "F1 Score: 0.21238938053097345\n",
      "Micro F1 Score: 0.9293650793650794\n",
      "Macro F1 Score: 0.5877069461857194\n",
      "ROC AUC: 0.8784379500509325\n",
      "Confusion Matrix:\n",
      "[[1159    3]\n",
      " [  86   12]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, test_predictions)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, test_predictions)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, test_predictions_proba)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4a1436-aac4-4d30-b67c-a87972d49971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2639f8-2f90-4dd2-94c3-e825be9fc910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "337c11de-f616-4124-ae72-30c3ffd68ea8",
   "metadata": {},
   "source": [
    "### ensemble methods (bagging and boosting) , stacking effect is not good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cf330b-dd91-418d-a83a-7d167ed7d0c5",
   "metadata": {},
   "source": [
    "### 3. boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef838f9d-e977-4cd7-b2fd-cb07110c63fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalanced + cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d04acc2-d0e8-40a8-bcbc-207716cfe74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9333333333333333\n",
      "Cross-validation Scores: [0.92261905 0.91964286 0.91964286 0.92552135 0.9225422 ]\n",
      "Mean CV Accuracy: 0.9219936634037925\n",
      "Test Accuracy: 0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data_cleaned.drop('status_label_encoded', axis=1)\n",
    "y = data_cleaned['status_label_encoded']\n",
    "\n",
    "# Split the data into training + validation and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Further split the training + validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define a Gradient Boosting classifier\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "\n",
    "# Train Gradient Boosting model\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_predictions = gb_classifier.predict(X_val)\n",
    "# Calculate accuracy on validation set\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Perform cross-validation on the train_val set\n",
    "cv_scores = cross_val_score(gb_classifier, X_train_val, y_train_val, cv=5)\n",
    "# Print cross-validat ion scores\n",
    "print(\"Cross-validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# # Retrain the model on the train_val set\n",
    "# gb_classifier.fit(X_train_val, y_train_val)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = gb_classifier.predict(X_test)\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f17295ec-2587-4231-ae5f-39eb874007d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.9285714285714286\n",
      "Macro F1 Score: 0.5933501635205691\n",
      "Test Accuracy: 0.9285714285714286\n",
      "Precision: 0.7222222222222222\n",
      "Recall: 0.1326530612244898\n",
      "F1 Score: 0.22413793103448276\n",
      "ROC AUC Score: 0.8521549755874811\n",
      "Confusion Matrix:\n",
      " [[1157    5]\n",
      " [  85   13]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "test_predictions_proba = gb_classifier.predict_proba(X_test)[:, 1]  # Probabilities for positive class\n",
    "roc_auc = roc_auc_score(y_test, test_predictions_proba)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc89faa4-c2e4-42b6-b932-055ea478309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoostingClassifier\n",
    "# SMOTE + CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75e8c233-c9f9-43c8-a47c-3b43f8fe8e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3449\n",
      "1    3449\n",
      "Name: status_label_encoded, dtype: int64\n",
      "Validation Accuracy: 0.9182539682539682\n",
      "Cross-validation Scores: [0.88357843 0.98223039 0.98284314 0.98835071 0.94849785]\n",
      "Mean CV Accuracy: 0.9571001039900938\n",
      "Test Accuracy: 0.919047619047619\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data_cleaned.drop('status_label_encoded', axis=1)\n",
    "y = data_cleaned['status_label_encoded']\n",
    "\n",
    "# Split the data into training + validation and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Further split the training + validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Apply SMOTE only on the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "# Print the number of samples after oversampling\n",
    "print(pd.Series(y_train_resampled).value_counts())\n",
    "\n",
    "# Define a Gradient Boosting classifier\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "  #AdaBoost less better result\n",
    "\n",
    "\n",
    "# Train Gradient Boosting model\n",
    "gb_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_predictions = gb_classifier.predict(X_val)\n",
    "# Calculate accuracy on validation set\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Merge resampled training and validation data\n",
    "X_train_val_reshaped = np.concatenate((X_train_resampled, X_val), axis=0)\n",
    "y_train_val_reshaped = np.concatenate((y_train_resampled, y_val), axis=0)\n",
    "\n",
    "\n",
    "# Perform cross-validation on the train_val set\n",
    "cv_scores = cross_val_score(gb_classifier, X_train_val_reshaped, y_train_val_reshaped, cv=5)\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# # Retrain the model on the train_val set\n",
    "# gb_classifier.fit(X_train_val_reshaped, y_train_val_reshaped)\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = gb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae375abf-8cae-40b9-a8dd-bff5c01250ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.919047619047619\n",
      "Macro F1 Score: 0.647275801121955\n",
      "Test Accuracy: 0.919047619047619\n",
      "Precision: 0.4642857142857143\n",
      "Recall: 0.2653061224489796\n",
      "F1 Score: 0.3376623376623377\n",
      "ROC AUC Score: 0.8762162352032036\n",
      "Confusion Matrix:\n",
      " [[1132   30]\n",
      " [  72   26]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "test_predictions_proba = gb_classifier.predict_proba(X_test)[:, 1]  # Probabilities for positive class\n",
    "roc_auc = roc_auc_score(y_test, test_predictions_proba)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "940bc75e-a98b-4733-a703-1ba2557058d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE + FS + GRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfc51d8a-266c-47a4-88d9-e87acb914dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3449\n",
      "1    3449\n",
      "Name: status_label_encoded, dtype: int64\n",
      "Selected Features:\n",
      "Index(['X4_last2year', 'X4_last3year', 'X7_last1year', 'X9_last1year',\n",
      "       'X9_last3year', 'X10_last2year', 'X10_last3year', 'X11_last1year',\n",
      "       'X11_last2year', 'X18_last1year', 'X18_last2year', 'X1_last3year_ycr',\n",
      "       'X5_last3year_ycr', 'X9_last1year_ycr', 'X9_last2year_ycr',\n",
      "       'X11_last1year_ycr', 'X13_last1year_ycr', 'X15_last1year_ycr',\n",
      "       'nyse_last1year', 'nyse_last3year', 'nasdaq_last3year',\n",
      "       'Division_encoded'],\n",
      "      dtype='object')\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 150}\n",
      "Validation Accuracy: 0.9142857142857143\n",
      "Test Accuracy: 0.9182539682539682\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data_cleaned.drop('status_label_encoded', axis=1)\n",
    "y = data_cleaned['status_label_encoded']\n",
    "\n",
    "# Split the data into training + validation and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Further split the training + validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Apply SMOTE only on the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print the number of samples after oversampling\n",
    "print(pd.Series(y_train_resampled).value_counts())\n",
    "\n",
    "# Define a Gradient Boosting classifier\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "  #AdaBoost less better result\n",
    "\n",
    "# Perform feature selection \n",
    "selector = SelectFromModel(estimator=gb_classifier, threshold='mean')  # median: worse recall, f1, AUC\n",
    "selector.fit(X_train_resampled, y_train_resampled)\n",
    "selected_features = X_train_resampled.columns[selector.get_support()]\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)\n",
    "\n",
    "# Transform the datasets\n",
    "X_train_selected = selector.transform(X_train_resampled)\n",
    "X_val_selected = selector.transform(X_val)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=gb_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Print the best parameters found by GridSearchCV\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Train Gradient Boosting model with the best parameters\n",
    "best_gb_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_predictions = best_gb_model.predict(X_val_selected)\n",
    "# Calculate accuracy on validation set\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "\n",
    "# # Combine resampled training set and validation set\n",
    "# X_train_val_combined = pd.concat([pd.DataFrame(X_train_selected), pd.DataFrame(X_val_selected)], axis=0)\n",
    "# y_train_val_combined = pd.concat([pd.Series(y_train_resampled), pd.Series(y_val)], axis=0)\n",
    "\n",
    "# # Train XGBoost model with train_val\n",
    "# best_gb_model.fit(X_train_val_combined, y_train_val_combined)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = best_gb_model.predict(X_test_selected)\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e719694f-7f25-482f-a936-dac876b96bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.9182539682539682\n",
      "Macro F1 Score: 0.6733607000923691\n",
      "Test Accuracy: 0.9182539682539682\n",
      "Precision: 0.4647887323943662\n",
      "Recall: 0.336734693877551\n",
      "F1 Score: 0.3905325443786982\n",
      "ROC AUC Score: 0.8445150865854087\n",
      "Confusion Matrix:\n",
      " [[1124   38]\n",
      " [  65   33]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "test_predictions_proba = best_gb_model.predict_proba(X_test_selected)[:, 1]  # Probabilities for positive class\n",
    "roc_auc = roc_auc_score(y_test, test_predictions_proba)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38c2b69f-e06f-43b8-9e5e-67fc8c279fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNDERSAMPLING + FS + GRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "517368a6-4120-48ef-9606-0c1cf43c946c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    329\n",
      "1    329\n",
      "Name: status_label_encoded, dtype: int64\n",
      "Selected Features:\n",
      "Index(['X2_last1year', 'X3_last1year', 'X5_last2year', 'X11_last1year',\n",
      "       'X11_last2year', 'X12_last1year', 'X13_last1year', 'X14_last1year',\n",
      "       'X14_last2year', 'X14_last3year', 'X15_last1year', 'X15_last3year',\n",
      "       'X17_last1year', 'X17_last3year', 'X6_last3year_ycr',\n",
      "       'X8_last2year_ycr', 'X8_last3year_ycr', 'X9_last1year_ycr',\n",
      "       'X10_last1year_ycr', 'X10_last3year_ycr', 'X11_last3year_ycr',\n",
      "       'X12_last1year_ycr', 'X12_last2year_ycr', 'X15_last1year_ycr',\n",
      "       'X15_last2year_ycr', 'X18_last3year_ycr', 'nyse_last3year',\n",
      "       'nasdaq_last2year', 'nasdaq_last3year', 'MajorGroup_encoded'],\n",
      "      dtype='object')\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "Validation Accuracy: 0.7317460317460317\n",
      "Test Accuracy: 0.7388888888888889\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data_cleaned.drop('status_label_encoded', axis=1)\n",
    "y = data_cleaned['status_label_encoded']\n",
    "\n",
    "# Split the data into training + validation and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Further split the training + validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define an undersampler\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "# Print the number of samples after oversampling\n",
    "print(pd.Series(y_train_resampled).value_counts())\n",
    "\n",
    "# Define a Gradient Boosting classifier\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "  #AdaBoost less better result\n",
    "\n",
    "# Perform feature selection \n",
    "selector = SelectFromModel(estimator=gb_classifier, threshold='mean')  # median: worse recall, f1, AUC\n",
    "selector.fit(X_train_resampled, y_train_resampled)\n",
    "selected_features = X_train_resampled.columns[selector.get_support()]\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)\n",
    "\n",
    "# Transform the datasets\n",
    "X_train_selected = selector.transform(X_train_resampled)\n",
    "X_val_selected = selector.transform(X_val)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=gb_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Print the best parameters found by GridSearchCV\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Train Gradient Boosting model with the best parameters\n",
    "best_gb_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_predictions = best_gb_model.predict(X_val_selected)\n",
    "# Calculate accuracy on validation set\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "\n",
    "# # Combine resampled training set and validation set\n",
    "# X_train_val_combined = pd.concat([pd.DataFrame(X_train_selected), pd.DataFrame(X_val_selected)], axis=0)\n",
    "# y_train_val_combined = pd.concat([pd.Series(y_train_resampled), pd.Series(y_val)], axis=0)\n",
    "\n",
    "# # Train XGBoost model with train_val\n",
    "# best_gb_model.fit(X_train_val_combined, y_train_val_combined)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = best_gb_model.predict(X_test_selected)\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8568cc01-b82a-4bb1-83ca-e18cb3533fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.7388888888888889\n",
      "Macro F1 Score: 0.5826045980552963\n",
      "Test Accuracy: 0.7388888888888889\n",
      "Precision: 0.20460358056265984\n",
      "Recall: 0.8163265306122449\n",
      "F1 Score: 0.32719836400818\n",
      "ROC AUC Score: 0.841388879131687\n",
      "Confusion Matrix:\n",
      " [[851 311]\n",
      " [ 18  80]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "test_predictions_proba = best_gb_model.predict_proba(X_test_selected)[:, 1]  # Probabilities for positive class\n",
    "roc_auc = roc_auc_score(y_test, test_predictions_proba)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defcff70-6308-4e57-8d2d-587922dfec0a",
   "metadata": {},
   "source": [
    "### 4. bagging method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eed50260-314f-4098-b0ec-81530abb4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBOOST :base_estimator\n",
    "#imbalance dataset + CV \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5971e293-b54a-4e9c-a5c3-783ec749d49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.930952380952381\n",
      "Cross-validation Scores: [0.92162698 0.92261905 0.91865079 0.92552135 0.9225422 ]\n",
      "Mean CV Accuracy: 0.9221920761022051\n",
      "Test Accuracy: 0.9325396825396826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data_cleaned.drop('status_label_encoded', axis=1)\n",
    "y = data_cleaned['status_label_encoded']\n",
    "\n",
    "# Split the data set into training set, validation set and test set\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 80% training, 20% validation\n",
    "\n",
    "# Define a XGBoost base estimator\n",
    "base_estimator = XGBClassifier(n_estimators=100, random_state=42)  #better than base_estimator=DecisionTreeClassifier\n",
    "# Define a bagging classifier\n",
    "bagging_classifier = BaggingClassifier(base_estimator=base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_predictions = bagging_classifier.predict(X_val)\n",
    "# Calculate accuracy on validation set\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Perform cross-validation on the train_val set\n",
    "cv_scores = cross_val_score(bagging_classifier, X_train_val, y_train_val, cv=5)\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# # Retrain the model on the train_val set\n",
    "# bagging_classifier.fit(X_train_val, y_train_val)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = bagging_classifier.predict(X_test)\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa22e5b6-98bb-4fc0-bf5e-75dfca1e4e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.9325396825396827\n",
      "Macro F1 Score: 0.6190659112007426\n",
      "Test Accuracy: 0.9325396825396826\n",
      "Precision: 0.8421052631578947\n",
      "Recall: 0.16326530612244897\n",
      "F1 Score: 0.2735042735042735\n",
      "ROC AUC Score: 0.8770416944746918\n",
      "Confusion Matrix:\n",
      " [[1159    3]\n",
      " [  82   16]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "test_predictions_proba = bagging_classifier.predict_proba(X_test)[:, 1]  # Probabilities for positive class\n",
    "roc_auc = roc_auc_score(y_test, test_predictions_proba)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f79727a-8ad0-4cc5-a82c-049948e22a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBOOST :base_estimator\n",
    "#smote + CV \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "262930f4-9a28-4983-84f2-32c0188487c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3449\n",
      "1    3449\n",
      "Name: status_label_encoded, dtype: int64\n",
      "Validation Accuracy: 0.930952380952381\n",
      "Cross-validation Scores: [0.85232843 0.98590686 0.98897059 0.99080319 0.94665849]\n",
      "Mean CV Accuracy: 0.9529335124607783\n",
      "Test Accuracy: 0.9301587301587302\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data_cleaned.drop('status_label_encoded', axis=1)\n",
    "y = data_cleaned['status_label_encoded']\n",
    "\n",
    "# Remove feature names from X\n",
    "X = X.values\n",
    "\n",
    "# Split the data set into training set, validation set and test set\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 80% training, 20% validation\n",
    "\n",
    "# Apply SMOTE only on the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "# Print the number of samples after oversampling\n",
    "print(pd.Series(y_train_resampled).value_counts())\n",
    "\n",
    "\n",
    "# Define a XGBoost base estimator\n",
    "base_estimator = XGBClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Define a bagging classifier\n",
    "bagging_classifier = BaggingClassifier(base_estimator=base_estimator, n_estimators=10, random_state=42, bootstrap_features=True)\n",
    "\n",
    "# Train the model on the training set\n",
    "bagging_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_predictions = bagging_classifier.predict(X_val)\n",
    "# Calculate accuracy on validation set\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Merge resampled training and validation data\n",
    "X_train_val_reshaped = np.concatenate((X_train_resampled, X_val), axis=0)\n",
    "y_train_val_reshaped = np.concatenate((y_train_resampled, y_val), axis=0)\n",
    "\n",
    "\n",
    "# Perform cross-validation on the train_val set\n",
    "cv_scores = cross_val_score(bagging_classifier, X_train_val_reshaped, y_train_val_reshaped, cv=5)\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# # Retrain the model on the train_val set\n",
    "# bagging_classifier.fit(X_train_val_reshaped, y_train_val_reshaped)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = bagging_classifier.predict(X_test)\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f72527d6-3546-4326-992f-0e8c5da4bd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.9301587301587302\n",
      "Macro F1 Score: 0.6759259259259259\n",
      "Test Accuracy: 0.9301587301587302\n",
      "Precision: 0.6086956521739131\n",
      "Recall: 0.2857142857142857\n",
      "F1 Score: 0.3888888888888889\n",
      "ROC AUC Score: 0.8782184130106431\n",
      "Confusion Matrix:\n",
      " [[1144   18]\n",
      " [  70   28]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "test_predictions_proba = bagging_classifier.predict_proba(X_test)[:, 1]  # Probabilities for positive class\n",
    "roc_auc = roc_auc_score(y_test, test_predictions_proba)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bac3e179-879d-45bd-aa79-78a8159cd6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBOOST :base_estimator \n",
    "#smote +  fs + grid research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25a28221-7abc-46f7-a626-693aecf66e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3449\n",
      "1    3449\n",
      "Name: status_label_encoded, dtype: int64\n",
      "Selected Features:\n",
      "Index(['X1_last3year', 'X4_last2year', 'X4_last3year', 'X9_last1year',\n",
      "       'X10_last2year', 'X10_last3year', 'X11_last1year', 'X11_last2year',\n",
      "       'X12_last1year', 'X16_last3year', 'X18_last1year', 'X18_last2year',\n",
      "       'X9_last2year_ycr', 'X13_last1year_ycr', 'X13_last2year_ycr',\n",
      "       'X15_last1year_ycr', 'nyse_last1year', 'nyse_last3year',\n",
      "       'nasdaq_last2year', 'nasdaq_last3year', 'Division_encoded',\n",
      "       'MajorGroup_encoded'],\n",
      "      dtype='object')\n",
      "Best Parameters: {'base_estimator__max_depth': 15, 'bootstrap': False, 'max_samples': 1.0, 'n_estimators': 75}\n",
      "Validation Accuracy: 0.9277777777777778\n",
      "Test Accuracy: 0.9261904761904762\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data_cleaned.drop('status_label_encoded', axis=1)\n",
    "y = data_cleaned['status_label_encoded']\n",
    "\n",
    "# Remove feature names from X\n",
    "X = X.values\n",
    "\n",
    "# Split the data set into training set, validation set and test set\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 80% training, 20% validation\n",
    "\n",
    "# Apply SMOTE only on the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "# Print the number of samples after oversampling\n",
    "print(pd.Series(y_train_resampled).value_counts())\n",
    "\n",
    "# Define a XGBoost base estimator\n",
    "base_estimator = XGBClassifier(n_estimators=100, random_state=42)\n",
    "# Define a bagging classifier\n",
    "bagging_classifier = BaggingClassifier(base_estimator=base_estimator, n_estimators=10, random_state=42, bootstrap_features=True)\n",
    "\n",
    "# Perform feature selection\n",
    "selector = SelectFromModel(estimator=base_estimator, threshold='mean')\n",
    "selector.fit(X_train_resampled, y_train_resampled)\n",
    "# print the selected colomn name\n",
    "support = selector.get_support()\n",
    "original_feature_names = data_cleaned.drop('status_label_encoded', axis=1).columns\n",
    "selected_feature_names = original_feature_names[support]\n",
    "print(\"Selected Features:\")\n",
    "print(selected_feature_names)\n",
    "\n",
    "\n",
    "X_train_selected = selector.transform(X_train_resampled)\n",
    "X_val_selected = selector.transform(X_val)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'base_estimator__max_depth': [5, 10, 15],\n",
    "    'n_estimators': [50, 75, 100],\n",
    "    'bootstrap': [True, False],\n",
    "    'max_samples': [0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=bagging_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Print the best parameters found by GridSearchCV\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "best_bagging_classifier = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_predictions = best_bagging_classifier.predict(X_val_selected)\n",
    "# Calculate accuracy on validation set\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "\n",
    "# # Combine resampled training set and validation set\n",
    "# X_train_val_combined = pd.concat([pd.DataFrame(X_train_selected), pd.DataFrame(X_val_selected)], axis=0)\n",
    "# y_train_val_combined = pd.concat([pd.Series(y_train_resampled), pd.Series(y_val)], axis=0)\n",
    "\n",
    "# # Train XGBoost model with train_val\n",
    "# best_bagging_classifier.fit(X_train_val_combined, y_train_val_combined)\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = best_bagging_classifier.predict(X_test_selected)\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd86cf97-ea18-427f-86d6-a75e21ea15c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.9261904761904762\n",
      "Macro F1 Score: 0.680338266384778\n",
      "Test Accuracy: 0.9261904761904762\n",
      "Precision: 0.543859649122807\n",
      "Recall: 0.3163265306122449\n",
      "F1 Score: 0.4\n",
      "ROC AUC Score: 0.8704204573395624\n",
      "Confusion Matrix:\n",
      " [[1136   26]\n",
      " [  67   31]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "test_predictions_proba = best_bagging_classifier.predict_proba(X_test_selected)[:, 1]  # Probabilities for positive class\n",
    "roc_auc = roc_auc_score(y_test, test_predictions_proba)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de830a16-0de6-4a8c-bdc9-afd1ce8655ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBOOST :base_estimator\n",
    "#undersampling +  fs + grid research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eef59895-ae77-44f3-a1c6-7c7584cd4815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    329\n",
      "1    329\n",
      "Name: status_label_encoded, dtype: int64\n",
      "Selected Features:\n",
      "Index(['X1_last1year', 'X2_last1year', 'X3_last2year', 'X4_last2year',\n",
      "       'X5_last1year', 'X5_last3year', 'X7_last1year', 'X10_last1year',\n",
      "       'X10_last3year', 'X11_last1year', 'X11_last2year', 'X12_last1year',\n",
      "       'X12_last3year', 'X13_last1year', 'X14_last2year', 'X14_last3year',\n",
      "       'X15_last2year', 'X16_last1year', 'X16_last2year', 'X5_last3year_ycr',\n",
      "       'X6_last3year_ycr', 'X7_last2year_ycr', 'X8_last3year_ycr',\n",
      "       'X9_last1year_ycr', 'X10_last1year_ycr', 'X12_last1year_ycr',\n",
      "       'X13_last1year_ycr', 'X15_last1year_ycr', 'X16_last1year_ycr',\n",
      "       'X18_last1year_ycr', 'X18_last2year_ycr', 'nyse_last1year',\n",
      "       'nyse_last2year', 'nyse_last3year', 'nasdaq_last1year',\n",
      "       'nasdaq_last2year', 'nasdaq_last3year', 'Division_encoded'],\n",
      "      dtype='object')\n",
      "Best Parameters: {'base_estimator__max_depth': 5, 'bootstrap': False, 'max_samples': 1.0, 'n_estimators': 75}\n",
      "Validation Accuracy: 0.7484126984126984\n",
      "Test Accuracy: 0.7547619047619047\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data_cleaned.drop('status_label_encoded', axis=1)\n",
    "y = data_cleaned['status_label_encoded']\n",
    "\n",
    "# Remove feature names from X\n",
    "X = X.values\n",
    "\n",
    "# Split the data set into training set, validation set and test set\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 80% training, 20% validation\n",
    "\n",
    "\n",
    "# Define an undersampler\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "# Print the number of samples after oversampling\n",
    "print(pd.Series(y_train_resampled).value_counts())\n",
    "\n",
    "\n",
    "# Define a XGBoost base estimator\n",
    "base_estimator = XGBClassifier(n_estimators=100, random_state=42)\n",
    "# Define a bagging classifier\n",
    "bagging_classifier = BaggingClassifier(base_estimator=base_estimator, n_estimators=10, random_state=42, bootstrap_features=True)\n",
    "\n",
    "# Perform feature selection\n",
    "selector = SelectFromModel(estimator=base_estimator, threshold='mean')\n",
    "selector.fit(X_train_resampled, y_train_resampled)\n",
    "# change NumPy into pandas DataFrame\n",
    "#df_train_resampled = pd.DataFrame(X_train_resampled)\n",
    "# print the selected colomn name\n",
    "support = selector.get_support()\n",
    "original_feature_names = data_cleaned.drop('status_label_encoded', axis=1).columns\n",
    "selected_feature_names = original_feature_names[support]\n",
    "print(\"Selected Features:\")\n",
    "print(selected_feature_names)\n",
    "\n",
    "\n",
    "X_train_selected = selector.transform(X_train_resampled)\n",
    "X_val_selected = selector.transform(X_val)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'base_estimator__max_depth': [5, 10, 15],\n",
    "    'n_estimators': [50, 75, 100],\n",
    "    'bootstrap': [True, False],\n",
    "    'max_samples': [0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=bagging_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Print the best parameters found by GridSearchCV\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "best_bagging_classifier = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_predictions = best_bagging_classifier.predict(X_val_selected)\n",
    "# Calculate accuracy on validation set\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# # Combine resampled training set and validation set\n",
    "# X_train_val_combined = pd.concat([pd.DataFrame(X_train_selected), pd.DataFrame(X_val_selected)], axis=0)\n",
    "# y_train_val_combined = pd.concat([pd.Series(y_train_resampled), pd.Series(y_val)], axis=0)\n",
    "\n",
    "# # Train XGBoost model with train_val\n",
    "# best_bagging_classifier.fit(X_train_val_combined, y_train_val_combined)\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = best_bagging_classifier.predict(X_test_selected)\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b6e92a8-815f-41d8-8e63-2f507886687c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.7547619047619047\n",
      "Macro F1 Score: 0.5978852154083065\n",
      "Test Accuracy: 0.7547619047619047\n",
      "Precision: 0.21866666666666668\n",
      "Recall: 0.8367346938775511\n",
      "F1 Score: 0.34672304439746293\n",
      "ROC AUC Score: 0.856106642312691\n",
      "Confusion Matrix:\n",
      " [[869 293]\n",
      " [ 16  82]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "test_predictions_proba = best_bagging_classifier.predict_proba(X_test_selected)[:, 1]  # Probabilities for positive class\n",
    "roc_auc = roc_auc_score(y_test, test_predictions_proba)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17952dbc-a52f-4dad-beb2-b4742a3298eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
