{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bb3c325-927d-40b8-8309-19c0c35ac3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb2e3631-6704-4cac-8a49-88743235ff8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in 'company_name' column: 8971\n",
      "Number of unique values in 'status_label' column: 2\n",
      "Number of unique values in 'Division' column: 10\n",
      "Number of unique values in 'MajorGroup' column: 73\n",
      "Number of unique values in 'last_year' column: 20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data set\n",
    "data = pd.read_csv(\"new_df_selected3_last3years_adjusted.csv\")\n",
    "\n",
    "\n",
    "unique_company_names = data['company_name'].nunique()\n",
    "unique_status_labels = data['status_label'].nunique()\n",
    "unique_divisions = data['Division'].nunique()\n",
    "unique_majorgroup = data['MajorGroup'].nunique()\n",
    "unique_last_year = data['last_year'].nunique()\n",
    "\n",
    "print(\"Number of unique values in 'company_name' column:\", unique_company_names)\n",
    "print(\"Number of unique values in 'status_label' column:\", unique_status_labels)\n",
    "print(\"Number of unique values in 'Division' column:\", unique_divisions)\n",
    "print(\"Number of unique values in 'MajorGroup' column:\", unique_majorgroup)\n",
    "print(\"Number of unique values in 'last_year' column:\", unique_last_year)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66af57c6-3d64-4eb2-8884-c4153dad6bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8971, 119)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc4a5663-66c6-4f87-84bb-ff9ab875eba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  company_name status_label Division  MajorGroup  last_year  X1_last1year  \\\n",
      "0          C_1        alive        D          37     2017.0         942.7   \n",
      "1          C_2        alive        D          36     2010.0        1107.7   \n",
      "2          C_3        alive        D          38     2008.0       12686.0   \n",
      "3          C_4        alive        D          28     2007.0      581502.0   \n",
      "4          C_5        alive        D          35     1999.0       28957.0   \n",
      "\n",
      "   X1_last2year  X1_last3year  X2_last1year  X2_last2year  ...  \\\n",
      "0         888.5         873.1       1524.70        1504.1  ...   \n",
      "1         900.2        1077.4       1474.50        1343.6  ...   \n",
      "2       13454.0       13582.0      21401.00       27171.0  ...   \n",
      "3      353541.0     1037047.0    1288165.00      927239.0  ...   \n",
      "4           NaN           NaN         42.21           NaN  ...   \n",
      "\n",
      "   nyse_last1year  nyse_last2year  nyse_last3year  nasdaq_last1year  \\\n",
      "0    11912.848307    10451.377523    10606.906738       6293.024211   \n",
      "1     7166.229940     6100.795776     8001.502441       2333.908345   \n",
      "2     8001.502441     9685.001790     8434.441610       2148.948334   \n",
      "3     9685.001790     8434.441610     7364.758301       2587.587504   \n",
      "4     6549.827474             NaN             NaN       2787.559998   \n",
      "\n",
      "   nasdaq_last2year  nasdaq_last3year  company_name_encoded  Division_encoded  \\\n",
      "0       5015.926717       4932.729126                     0                 3   \n",
      "1       1856.529999       2148.948334                  1111                 3   \n",
      "2       2587.587504       2278.996664                  2222                 3   \n",
      "3       2278.996664       2100.603343                  3333                 3   \n",
      "4               NaN               NaN                  4444                 3   \n",
      "\n",
      "   MajorGroup_encoded  status_label_encoded  \n",
      "0                  29                     0  \n",
      "1                  28                     0  \n",
      "2                  30                     0  \n",
      "3                  20                     0  \n",
      "4                  27                     0  \n",
      "\n",
      "[5 rows x 123 columns]\n"
     ]
    }
   ],
   "source": [
    "# Encoding non-numeric columns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "# Label-encode the company_name column\n",
    "data['company_name_encoded'] = label_encoder.fit_transform(data['company_name'])\n",
    "\n",
    "\n",
    "# Label-encode the Division column\n",
    "data['Division_encoded'] = label_encoder.fit_transform(data['Division'])\n",
    "\n",
    "# Label-encode MajorGroup columns\n",
    "data['MajorGroup_encoded'] = label_encoder.fit_transform(data['MajorGroup'])\n",
    "#When using label encoding for feature encoding, the sequential relationship between categories will not be introduced and will not have an impact on prediction.\n",
    "\n",
    "# Encode the label of the status_label column\n",
    "data['status_label_encoded'] = label_encoder.fit_transform(data['status_label'])\n",
    "#With only two categories, it may be simpler and more appropriate to use label encoding as it maps the categories to 0 and 1, suitable for use in tree-based models. \n",
    "#If use one-hot encoding, a new column will be generated\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "374fe89d-42d2-472f-8724-dcc6f06dff33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8971, 123)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "381247f3-2cdf-4adf-b51a-e16ec84e1347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with missing values: 2673\n"
     ]
    }
   ],
   "source": [
    "missing_rows_count = data.isnull().any(axis=1).sum()\n",
    "print(\"Number of rows with missing values:\", missing_rows_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b98d5d1a-22e0-4ee6-8fc9-f156a2a97b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6298, 117)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete rows with missing values\n",
    "data_cleaned = data.dropna()\n",
    "# Delete non-numeric columns that are not encoded\n",
    "# Delete specified column\n",
    "data_cleaned = data_cleaned.drop(['company_name', 'status_label', 'Division', 'MajorGroup', 'last_year', 'company_name_encoded'], axis=1)\n",
    "\n",
    "data_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22f1ba13-272c-4957-96db-dd37c4602510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       X1_last1year  X1_last2year  X1_last3year  X2_last1year  X2_last2year  \\\n",
       "0            942.7         888.5         873.1       1524.70       1504.10   \n",
       "1           1107.7         900.2        1077.4       1474.50       1343.60   \n",
       "2          12686.0       13454.0       13582.0      21401.00      27171.00   \n",
       "3         581502.0      353541.0     1037047.0    1288165.00     927239.00   \n",
       "5           6838.0        6642.0        5935.0      25088.00      25438.00   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "8966       10566.0       11738.0        9599.0      28278.00      26206.00   \n",
       "8967        3369.0        9049.0       21381.0       3466.00       9198.00   \n",
       "8968        2482.2        2340.6        2071.2       9401.50      10252.40   \n",
       "8969         931.6        1032.7         829.3       2810.20       2542.00   \n",
       "8970       82589.0      135207.0       63971.0       1625.37       1736.11   \n",
       "\n",
       "      X2_last3year  X3_last1year  X3_last2year  X3_last3year  X4_last1year  \\\n",
       "0         1442.100       1413.20      1422.700        1354.9         177.2   \n",
       "1         1921.000        677.20       600.500         870.7         650.8   \n",
       "2        14341.000      19334.00        17.589       15454.0          23.0   \n",
       "3         1623.383        267.81    229115.000      150257.0         300.0   \n",
       "5        25175.000      18138.00     16935.000       20232.0        9253.0   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "8966     23442.000      31288.00     26885.000       22127.0        8497.0   \n",
       "8967     21782.000        208.00      1077.000        4972.0           0.0   \n",
       "8968     10054.100        966.70      1833.200        1723.3        5350.7   \n",
       "8969      2247.400       1475.90      1269.600        1190.4        1409.5   \n",
       "8970   1746235.000      68817.00     66527.000       69074.0      632122.0   \n",
       "\n",
       "      ...  X18_last3year_ycr  nyse_last1year  nyse_last2year  nyse_last3year  \\\n",
       "0     ...           0.009996    11912.848307    10451.377523    10606.906738   \n",
       "1     ...           0.111583     7166.229940     6100.795776     8001.502441   \n",
       "2     ...           0.115936     8001.502441     9685.001790     8434.441610   \n",
       "3     ...          -0.670632     9685.001790     8434.441610     7364.758301   \n",
       "5     ...           0.117916     7166.229940     6100.795776     8001.502441   \n",
       "...   ...                ...             ...             ...             ...   \n",
       "8966  ...          -0.096823    12593.500651    11912.848307    10451.377523   \n",
       "8967  ...          -0.283315    11912.848307    10451.377523    10606.906738   \n",
       "8968  ...           0.418174    12593.500651    11912.848307    10451.377523   \n",
       "8969  ...           0.076355    12593.500651    11912.848307    10451.377523   \n",
       "8970  ...        1019.074141    12593.500651    11912.848307    10451.377523   \n",
       "\n",
       "      nasdaq_last1year  nasdaq_last2year  nasdaq_last3year  Division_encoded  \\\n",
       "0          6293.024211       5015.926717       4932.729126                 3   \n",
       "1          2333.908345       1856.529999       2148.948334                 3   \n",
       "2          2148.948334       2587.587504       2278.996664                 3   \n",
       "3          2587.587504       2278.996664       2100.603343                 3   \n",
       "5          2333.908345       1856.529999       2148.948334                 4   \n",
       "...                ...               ...               ...               ...   \n",
       "8966       7405.502482       6293.024211       5015.926717                 3   \n",
       "8967       6293.024211       5015.926717       4932.729126                 3   \n",
       "8968       7405.502482       6293.024211       5015.926717                 3   \n",
       "8969       7405.502482       6293.024211       5015.926717                 8   \n",
       "8970       7405.502482       6293.024211       5015.926717                 4   \n",
       "\n",
       "      MajorGroup_encoded  status_label_encoded  \n",
       "0                     29                     0  \n",
       "1                     28                     0  \n",
       "2                     30                     0  \n",
       "3                     20                     0  \n",
       "5                     36                     1  \n",
       "...                  ...                   ...  \n",
       "8966                  20                     0  \n",
       "8967                  30                     0  \n",
       "8968                  20                     0  \n",
       "8969                  60                     0  \n",
       "8970                  35                     0  \n",
       "\n",
       "[6298 rows x 117 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89dd5f1e-dc82-4769-b937-5bb68e3d9f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5784\n",
      "1     514\n",
      "Name: status_label_encoded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "status_counts = data_cleaned['status_label_encoded'].value_counts()\n",
    "print(status_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d1349d6-3e68-4324-9dda-b3b2fe5c69fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#the impact of imbalanced datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf429e3-f9cd-4221-8584-475274b9b8b0",
   "metadata": {},
   "source": [
    "### 1.1 imbalance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06c14c50-9aac-439c-a964-b0a4041f0458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_last1year: (6298, 40)\n",
      "Shape of X_last2year: (6298, 40)\n",
      "Shape of X_last3year: (6298, 40)\n",
      "Shape of y: (6298,)\n",
      "Shape of X_last1year_scaled: (6298, 40)\n",
      "Shape of X_last2year_scaled: (6298, 40)\n",
      "Shape of X_last3year_scaled: (6298, 40)\n",
      "Shape of X_combined_reshaped: (6298, 3, 40)\n",
      "Shape of X_train: (3778, 3, 40)\n",
      "Shape of X_val: (1260, 3, 40)\n",
      "Shape of X_test: (1260, 3, 40)\n",
      "Epoch 1/100\n",
      "237/237 - 3s - 15ms/step - accuracy: 0.8941 - loss: 0.3255 - val_accuracy: 0.9310 - val_loss: 0.2239\n",
      "Epoch 2/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9161 - loss: 0.2493 - val_accuracy: 0.9310 - val_loss: 0.2194\n",
      "Epoch 3/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9179 - loss: 0.2403 - val_accuracy: 0.9325 - val_loss: 0.2139\n",
      "Epoch 4/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9177 - loss: 0.2295 - val_accuracy: 0.9310 - val_loss: 0.2101\n",
      "Epoch 5/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9203 - loss: 0.2251 - val_accuracy: 0.9286 - val_loss: 0.2141\n",
      "Epoch 6/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9211 - loss: 0.2177 - val_accuracy: 0.9278 - val_loss: 0.2145\n",
      "Epoch 7/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9224 - loss: 0.2133 - val_accuracy: 0.9302 - val_loss: 0.2152\n",
      "Epoch 8/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9251 - loss: 0.2078 - val_accuracy: 0.9294 - val_loss: 0.2156\n",
      "Epoch 9/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9272 - loss: 0.2026 - val_accuracy: 0.9254 - val_loss: 0.2287\n",
      "Epoch 10/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9280 - loss: 0.1999 - val_accuracy: 0.9286 - val_loss: 0.2235\n",
      "Epoch 11/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9288 - loss: 0.1933 - val_accuracy: 0.9254 - val_loss: 0.2293\n",
      "Epoch 12/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9328 - loss: 0.1878 - val_accuracy: 0.9246 - val_loss: 0.2305\n",
      "Epoch 13/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9349 - loss: 0.1846 - val_accuracy: 0.9222 - val_loss: 0.2324\n",
      "Epoch 14/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9333 - loss: 0.1819 - val_accuracy: 0.9238 - val_loss: 0.2323\n",
      "Epoch 15/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9349 - loss: 0.1775 - val_accuracy: 0.9230 - val_loss: 0.2397\n",
      "Epoch 16/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9404 - loss: 0.1731 - val_accuracy: 0.9135 - val_loss: 0.2496\n",
      "Epoch 17/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9389 - loss: 0.1706 - val_accuracy: 0.9206 - val_loss: 0.2395\n",
      "Epoch 18/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9412 - loss: 0.1656 - val_accuracy: 0.9222 - val_loss: 0.2436\n",
      "Epoch 19/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9383 - loss: 0.1634 - val_accuracy: 0.9190 - val_loss: 0.2560\n",
      "Epoch 20/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9428 - loss: 0.1601 - val_accuracy: 0.9175 - val_loss: 0.2539\n",
      "Epoch 21/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9431 - loss: 0.1556 - val_accuracy: 0.9143 - val_loss: 0.2604\n",
      "Epoch 22/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9479 - loss: 0.1496 - val_accuracy: 0.9198 - val_loss: 0.2638\n",
      "Epoch 23/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9468 - loss: 0.1479 - val_accuracy: 0.9167 - val_loss: 0.2694\n",
      "Epoch 24/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9479 - loss: 0.1441 - val_accuracy: 0.9190 - val_loss: 0.2748\n",
      "Epoch 25/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9481 - loss: 0.1424 - val_accuracy: 0.9206 - val_loss: 0.2739\n",
      "Epoch 26/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9510 - loss: 0.1381 - val_accuracy: 0.9127 - val_loss: 0.2834\n",
      "Epoch 27/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9537 - loss: 0.1342 - val_accuracy: 0.9206 - val_loss: 0.2919\n",
      "Epoch 28/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9513 - loss: 0.1314 - val_accuracy: 0.9087 - val_loss: 0.2999\n",
      "Epoch 29/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9534 - loss: 0.1300 - val_accuracy: 0.9048 - val_loss: 0.3014\n",
      "Epoch 30/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9550 - loss: 0.1237 - val_accuracy: 0.9127 - val_loss: 0.3027\n",
      "Epoch 31/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9550 - loss: 0.1255 - val_accuracy: 0.9032 - val_loss: 0.3193\n",
      "Epoch 32/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9571 - loss: 0.1234 - val_accuracy: 0.9151 - val_loss: 0.3100\n",
      "Epoch 33/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9555 - loss: 0.1175 - val_accuracy: 0.8944 - val_loss: 0.3302\n",
      "Epoch 34/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9566 - loss: 0.1127 - val_accuracy: 0.9183 - val_loss: 0.3344\n",
      "Epoch 35/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9587 - loss: 0.1103 - val_accuracy: 0.9032 - val_loss: 0.3312\n",
      "Epoch 36/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9616 - loss: 0.1097 - val_accuracy: 0.8921 - val_loss: 0.3592\n",
      "Epoch 37/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9606 - loss: 0.1070 - val_accuracy: 0.9167 - val_loss: 0.3420\n",
      "Epoch 38/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9603 - loss: 0.1016 - val_accuracy: 0.9143 - val_loss: 0.3596\n",
      "Epoch 39/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9621 - loss: 0.1018 - val_accuracy: 0.9040 - val_loss: 0.3729\n",
      "Epoch 40/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9635 - loss: 0.0988 - val_accuracy: 0.9119 - val_loss: 0.3561\n",
      "Epoch 41/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9637 - loss: 0.0959 - val_accuracy: 0.8976 - val_loss: 0.3813\n",
      "Epoch 42/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9651 - loss: 0.0940 - val_accuracy: 0.8810 - val_loss: 0.4064\n",
      "Epoch 43/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9664 - loss: 0.0922 - val_accuracy: 0.8794 - val_loss: 0.3980\n",
      "Epoch 44/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9669 - loss: 0.0884 - val_accuracy: 0.9048 - val_loss: 0.3842\n",
      "Epoch 45/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9680 - loss: 0.0874 - val_accuracy: 0.9016 - val_loss: 0.3841\n",
      "Epoch 46/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9719 - loss: 0.0822 - val_accuracy: 0.9087 - val_loss: 0.4036\n",
      "Epoch 47/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9669 - loss: 0.0822 - val_accuracy: 0.9008 - val_loss: 0.4098\n",
      "Epoch 48/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9725 - loss: 0.0773 - val_accuracy: 0.9016 - val_loss: 0.4190\n",
      "Epoch 49/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9711 - loss: 0.0767 - val_accuracy: 0.9103 - val_loss: 0.4102\n",
      "Epoch 50/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9701 - loss: 0.0764 - val_accuracy: 0.8960 - val_loss: 0.4280\n",
      "Epoch 51/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9735 - loss: 0.0679 - val_accuracy: 0.9103 - val_loss: 0.4396\n",
      "Epoch 52/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9719 - loss: 0.0695 - val_accuracy: 0.9008 - val_loss: 0.4715\n",
      "Epoch 53/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9714 - loss: 0.0710 - val_accuracy: 0.9071 - val_loss: 0.4408\n",
      "Epoch 54/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9749 - loss: 0.0688 - val_accuracy: 0.9167 - val_loss: 0.4390\n",
      "Epoch 55/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9775 - loss: 0.0623 - val_accuracy: 0.9111 - val_loss: 0.4536\n",
      "Epoch 56/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9770 - loss: 0.0617 - val_accuracy: 0.9071 - val_loss: 0.4822\n",
      "Epoch 57/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9759 - loss: 0.0607 - val_accuracy: 0.9040 - val_loss: 0.4523\n",
      "Epoch 58/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9796 - loss: 0.0571 - val_accuracy: 0.9079 - val_loss: 0.4688\n",
      "Epoch 59/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9796 - loss: 0.0560 - val_accuracy: 0.8944 - val_loss: 0.4942\n",
      "Epoch 60/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9820 - loss: 0.0533 - val_accuracy: 0.9071 - val_loss: 0.5006\n",
      "Epoch 61/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9820 - loss: 0.0488 - val_accuracy: 0.9079 - val_loss: 0.5155\n",
      "Epoch 62/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9841 - loss: 0.0463 - val_accuracy: 0.8929 - val_loss: 0.5247\n",
      "Epoch 63/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9820 - loss: 0.0482 - val_accuracy: 0.8968 - val_loss: 0.5594\n",
      "Epoch 64/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9831 - loss: 0.0486 - val_accuracy: 0.8881 - val_loss: 0.5593\n",
      "Epoch 65/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9817 - loss: 0.0480 - val_accuracy: 0.8937 - val_loss: 0.5544\n",
      "Epoch 66/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9865 - loss: 0.0416 - val_accuracy: 0.8984 - val_loss: 0.5518\n",
      "Epoch 67/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9844 - loss: 0.0404 - val_accuracy: 0.8921 - val_loss: 0.5735\n",
      "Epoch 68/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9841 - loss: 0.0476 - val_accuracy: 0.9000 - val_loss: 0.5530\n",
      "Epoch 69/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9884 - loss: 0.0376 - val_accuracy: 0.9008 - val_loss: 0.5940\n",
      "Epoch 70/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9868 - loss: 0.0363 - val_accuracy: 0.8905 - val_loss: 0.5754\n",
      "Epoch 71/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9868 - loss: 0.0371 - val_accuracy: 0.8905 - val_loss: 0.6190\n",
      "Epoch 72/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9862 - loss: 0.0367 - val_accuracy: 0.8992 - val_loss: 0.6300\n",
      "Epoch 73/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9854 - loss: 0.0411 - val_accuracy: 0.8937 - val_loss: 0.6312\n",
      "Epoch 74/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9891 - loss: 0.0344 - val_accuracy: 0.9016 - val_loss: 0.6299\n",
      "Epoch 75/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9897 - loss: 0.0313 - val_accuracy: 0.8960 - val_loss: 0.6420\n",
      "Epoch 76/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9899 - loss: 0.0282 - val_accuracy: 0.8921 - val_loss: 0.6516\n",
      "Epoch 77/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9894 - loss: 0.0321 - val_accuracy: 0.8968 - val_loss: 0.6497\n",
      "Epoch 78/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9889 - loss: 0.0315 - val_accuracy: 0.9016 - val_loss: 0.6513\n",
      "Epoch 79/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9881 - loss: 0.0355 - val_accuracy: 0.9087 - val_loss: 0.6509\n",
      "Epoch 80/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9905 - loss: 0.0285 - val_accuracy: 0.9103 - val_loss: 0.6580\n",
      "Epoch 81/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9881 - loss: 0.0316 - val_accuracy: 0.9048 - val_loss: 0.6620\n",
      "Epoch 82/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9894 - loss: 0.0301 - val_accuracy: 0.8992 - val_loss: 0.6631\n",
      "Epoch 83/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9886 - loss: 0.0292 - val_accuracy: 0.8960 - val_loss: 0.6842\n",
      "Epoch 84/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9915 - loss: 0.0241 - val_accuracy: 0.9000 - val_loss: 0.6783\n",
      "Epoch 85/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9910 - loss: 0.0269 - val_accuracy: 0.9016 - val_loss: 0.6956\n",
      "Epoch 86/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9905 - loss: 0.0291 - val_accuracy: 0.8865 - val_loss: 0.7507\n",
      "Epoch 87/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9910 - loss: 0.0292 - val_accuracy: 0.9016 - val_loss: 0.7325\n",
      "Epoch 88/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9910 - loss: 0.0257 - val_accuracy: 0.9063 - val_loss: 0.7163\n",
      "Epoch 89/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9926 - loss: 0.0219 - val_accuracy: 0.8976 - val_loss: 0.7272\n",
      "Epoch 90/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9921 - loss: 0.0211 - val_accuracy: 0.9040 - val_loss: 0.7381\n",
      "Epoch 91/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9931 - loss: 0.0229 - val_accuracy: 0.8929 - val_loss: 0.7387\n",
      "Epoch 92/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9913 - loss: 0.0226 - val_accuracy: 0.8929 - val_loss: 0.7361\n",
      "Epoch 93/100\n",
      "237/237 - 1s - 3ms/step - accuracy: 0.9921 - loss: 0.0238 - val_accuracy: 0.8881 - val_loss: 0.7775\n",
      "Epoch 94/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9915 - loss: 0.0253 - val_accuracy: 0.8984 - val_loss: 0.7572\n",
      "Epoch 95/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9934 - loss: 0.0193 - val_accuracy: 0.8992 - val_loss: 0.7586\n",
      "Epoch 96/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9944 - loss: 0.0195 - val_accuracy: 0.8873 - val_loss: 0.8047\n",
      "Epoch 97/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9894 - loss: 0.0261 - val_accuracy: 0.9024 - val_loss: 0.7602\n",
      "Epoch 98/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9929 - loss: 0.0206 - val_accuracy: 0.8944 - val_loss: 0.7766\n",
      "Epoch 99/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9950 - loss: 0.0172 - val_accuracy: 0.8929 - val_loss: 0.8000\n",
      "Epoch 100/100\n",
      "237/237 - 1s - 4ms/step - accuracy: 0.9936 - loss: 0.0171 - val_accuracy: 0.8944 - val_loss: 0.8057\n",
      "test loss: 0.7846136689186096\n",
      "Test accuracy: 0.9007936716079712\n"
     ]
    }
   ],
   "source": [
    "# Feature column names\n",
    "last1year_features = []\n",
    "last2year_features = []\n",
    "last3year_features = []\n",
    "\n",
    "# Loop to build list of feature column names\n",
    "for i in range(1, 19):\n",
    "    last1year_features.append(f'X{i}_last1year')\n",
    "    last1year_features.append(f'X{i}_last1year_ycr')\n",
    "    last2year_features.append(f'X{i}_last2year')\n",
    "    last2year_features.append(f'X{i}_last2year_ycr')\n",
    "    last3year_features.append(f'X{i}_last3year')\n",
    "    last3year_features.append(f'X{i}_last3year_ycr')\n",
    "\n",
    "last1year_features.extend(['nyse_last1year', 'nasdaq_last1year', 'Division_encoded', 'MajorGroup_encoded'])\n",
    "last2year_features.extend(['nyse_last2year', 'nasdaq_last2year', 'Division_encoded', 'MajorGroup_encoded'])\n",
    "last3year_features.extend(['nyse_last3year', 'nasdaq_last3year', 'Division_encoded', 'MajorGroup_encoded'])\n",
    "\n",
    "# Define target column name\n",
    "target_column = 'status_label_encoded'\n",
    "\n",
    "# Extract features and target\n",
    "X_last1year = data_cleaned[last1year_features].values\n",
    "X_last2year = data_cleaned[last2year_features].values\n",
    "X_last3year = data_cleaned[last3year_features].values\n",
    "y = data_cleaned[target_column].values\n",
    "\n",
    "# Print data structure\n",
    "print(\"Shape of X_last1year:\", X_last1year.shape)\n",
    "print(\"Shape of X_last2year:\", X_last2year.shape)\n",
    "print(\"Shape of X_last3year:\", X_last3year.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Data Standardization\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the scaler\n",
    "scaler = StandardScaler()\n",
    "# Fit the scaler on the entire data set\n",
    "scaler.fit(np.concatenate((X_last1year, X_last2year, X_last3year,), axis=0))\n",
    "# Transform each year's data using the same scaler\n",
    "X_last1year_scaled = scaler.transform(X_last1year)\n",
    "X_last2year_scaled = scaler.transform(X_last2year)\n",
    "X_last3year_scaled = scaler.transform(X_last3year)\n",
    "\n",
    "# Reshape features to 3D arrays [samples, time steps, features]\n",
    "X_last1year_reshaped = np.reshape(X_last1year_scaled, (X_last1year_scaled.shape[0], 1, X_last1year_scaled.shape[1]))\n",
    "X_last2year_reshaped = np.reshape(X_last2year_scaled, (X_last2year_scaled.shape[0], 1, X_last2year_scaled.shape[1]))\n",
    "X_last3year_reshaped = np.reshape(X_last3year_scaled, (X_last3year_scaled.shape[0], 1, X_last3year_scaled.shape[1]))\n",
    "\n",
    "# Combine last1year and last2year features along the time step dimension\n",
    "X_combined_reshaped = np.concatenate((X_last3year_reshaped, X_last2year_reshaped, X_last1year_reshaped), axis=1)\n",
    "#First use data from the past two years (X_last3year_reshaped), then data from the past years \n",
    "\n",
    "# Print data structure\n",
    "print(\"Shape of X_last1year_scaled:\", X_last1year_scaled.shape)\n",
    "print(\"Shape of X_last2year_scaled:\", X_last2year_scaled.shape)\n",
    "print(\"Shape of X_last3year_scaled:\", X_last3year_scaled.shape)\n",
    "print(\"Shape of X_combined_reshaped:\", X_combined_reshaped.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_combined_reshaped, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42) # 0.8 * 0.25 = 0.2\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_val:\", X_val.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import LSTM, Dense, Dropout, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define LSTM model\n",
    "inputs = Input(shape=(3, X_train.shape[2]))  # (2, number of features) Accepts data with two time steps as input, and the first time step is the data of the past two years and the second time step is the data of the past year.\n",
    "lstm_layer = LSTM(100)(inputs)\n",
    "dropout_layer = Dropout(0.2)(lstm_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(dropout_layer)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output_layer)\n",
    "\n",
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_val, y_val), verbose=2)\n",
    "\n",
    "## Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"test loss:\", loss)\n",
    "print(\"Test accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42a47fdb-237f-4a7f-a793-d74da76a19a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "Accuracy: 0.9007936507936508\n",
      "Recall: 0.21428571428571427\n",
      "Precision: 0.30434782608695654\n",
      "F1 Score: 0.25149700598802394\n",
      "Micro F1 Score: 0.9007936507936508\n",
      "Macro F1 Score: 0.5991866670399109\n",
      "ROC AUC: 0.7510801222382241\n",
      "Confusion Matrix:\n",
      "[[1114   48]\n",
      " [  77   21]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8edf6c-8229-4253-bf85-d6e072f7c3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8faad794-6004-4df9-ae78-14c7f0295abe",
   "metadata": {},
   "source": [
    "### 1.2 SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9907ce24-5d26-46d2-a055-9be7d19dfd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_last1year: (6298, 40)\n",
      "Shape of X_last2year: (6298, 40)\n",
      "Shape of X_last3year: (6298, 40)\n",
      "Shape of y: (6298,)\n",
      "Shape of X_last1year_scaled: (6298, 40)\n",
      "Shape of X_last2year_scaled: (6298, 40)\n",
      "Shape of X_last3year_scaled: (6298, 40)\n",
      "Shape of X_combined_reshaped: (6298, 3, 40)\n",
      "Shape of X_train: (3778, 3, 40)\n",
      "Shape of X_val: (1260, 3, 40)\n",
      "Shape of X_test: (1260, 3, 40)\n",
      "Shape of X_train_resampled: (6898, 120)\n",
      "Shape of X_train_resampled: (6898, 3, 40)\n",
      "Epoch 1/100\n",
      "432/432 - 3s - 8ms/step - accuracy: 0.7231 - loss: 0.5310 - val_accuracy: 0.6127 - val_loss: 0.6013\n",
      "Epoch 2/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.7925 - loss: 0.4376 - val_accuracy: 0.7698 - val_loss: 0.4359\n",
      "Epoch 3/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.8231 - loss: 0.3874 - val_accuracy: 0.7286 - val_loss: 0.5113\n",
      "Epoch 4/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.8444 - loss: 0.3459 - val_accuracy: 0.7929 - val_loss: 0.4134\n",
      "Epoch 5/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.8600 - loss: 0.3181 - val_accuracy: 0.8175 - val_loss: 0.3927\n",
      "Epoch 6/100\n",
      "432/432 - 2s - 4ms/step - accuracy: 0.8759 - loss: 0.2883 - val_accuracy: 0.7365 - val_loss: 0.6174\n",
      "Epoch 7/100\n",
      "432/432 - 2s - 4ms/step - accuracy: 0.8901 - loss: 0.2660 - val_accuracy: 0.8103 - val_loss: 0.4141\n",
      "Epoch 8/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.8988 - loss: 0.2413 - val_accuracy: 0.7897 - val_loss: 0.4578\n",
      "Epoch 9/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9111 - loss: 0.2167 - val_accuracy: 0.8230 - val_loss: 0.4377\n",
      "Epoch 10/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9182 - loss: 0.1968 - val_accuracy: 0.8476 - val_loss: 0.4208\n",
      "Epoch 11/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9323 - loss: 0.1776 - val_accuracy: 0.8365 - val_loss: 0.4507\n",
      "Epoch 12/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9395 - loss: 0.1588 - val_accuracy: 0.8389 - val_loss: 0.4882\n",
      "Epoch 13/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9448 - loss: 0.1428 - val_accuracy: 0.8460 - val_loss: 0.5127\n",
      "Epoch 14/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9522 - loss: 0.1311 - val_accuracy: 0.8524 - val_loss: 0.5276\n",
      "Epoch 15/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9572 - loss: 0.1181 - val_accuracy: 0.8563 - val_loss: 0.5410\n",
      "Epoch 16/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9613 - loss: 0.1096 - val_accuracy: 0.8349 - val_loss: 0.5886\n",
      "Epoch 17/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9600 - loss: 0.1059 - val_accuracy: 0.8921 - val_loss: 0.4989\n",
      "Epoch 18/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9667 - loss: 0.0935 - val_accuracy: 0.8294 - val_loss: 0.6173\n",
      "Epoch 19/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9672 - loss: 0.0882 - val_accuracy: 0.8770 - val_loss: 0.5220\n",
      "Epoch 20/100\n",
      "432/432 - 3s - 6ms/step - accuracy: 0.9723 - loss: 0.0798 - val_accuracy: 0.8786 - val_loss: 0.5492\n",
      "Epoch 21/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9745 - loss: 0.0729 - val_accuracy: 0.8714 - val_loss: 0.5872\n",
      "Epoch 22/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9754 - loss: 0.0658 - val_accuracy: 0.8683 - val_loss: 0.6291\n",
      "Epoch 23/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9755 - loss: 0.0685 - val_accuracy: 0.8786 - val_loss: 0.5977\n",
      "Epoch 24/100\n",
      "432/432 - 2s - 4ms/step - accuracy: 0.9754 - loss: 0.0610 - val_accuracy: 0.8706 - val_loss: 0.6172\n",
      "Epoch 25/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9813 - loss: 0.0521 - val_accuracy: 0.8905 - val_loss: 0.6492\n",
      "Epoch 26/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9814 - loss: 0.0508 - val_accuracy: 0.8738 - val_loss: 0.7071\n",
      "Epoch 27/100\n",
      "432/432 - 2s - 4ms/step - accuracy: 0.9838 - loss: 0.0475 - val_accuracy: 0.8738 - val_loss: 0.6875\n",
      "Epoch 28/100\n",
      "432/432 - 2s - 4ms/step - accuracy: 0.9842 - loss: 0.0440 - val_accuracy: 0.8913 - val_loss: 0.6744\n",
      "Epoch 29/100\n",
      "432/432 - 2s - 3ms/step - accuracy: 0.9852 - loss: 0.0416 - val_accuracy: 0.8706 - val_loss: 0.6913\n",
      "Epoch 30/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9851 - loss: 0.0427 - val_accuracy: 0.8937 - val_loss: 0.6759\n",
      "Epoch 31/100\n",
      "432/432 - 2s - 4ms/step - accuracy: 0.9839 - loss: 0.0452 - val_accuracy: 0.8714 - val_loss: 0.7420\n",
      "Epoch 32/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9861 - loss: 0.0419 - val_accuracy: 0.8778 - val_loss: 0.6986\n",
      "Epoch 33/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9893 - loss: 0.0338 - val_accuracy: 0.8897 - val_loss: 0.7254\n",
      "Epoch 34/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9883 - loss: 0.0338 - val_accuracy: 0.8944 - val_loss: 0.7096\n",
      "Epoch 35/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9878 - loss: 0.0348 - val_accuracy: 0.8937 - val_loss: 0.7106\n",
      "Epoch 36/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9891 - loss: 0.0281 - val_accuracy: 0.8627 - val_loss: 0.8129\n",
      "Epoch 37/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9872 - loss: 0.0326 - val_accuracy: 0.8952 - val_loss: 0.7782\n",
      "Epoch 38/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9919 - loss: 0.0247 - val_accuracy: 0.8921 - val_loss: 0.7867\n",
      "Epoch 39/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9880 - loss: 0.0358 - val_accuracy: 0.8833 - val_loss: 0.7485\n",
      "Epoch 40/100\n",
      "432/432 - 2s - 4ms/step - accuracy: 0.9906 - loss: 0.0290 - val_accuracy: 0.8754 - val_loss: 0.8188\n",
      "Epoch 41/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9917 - loss: 0.0244 - val_accuracy: 0.8968 - val_loss: 0.7571\n",
      "Epoch 42/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9913 - loss: 0.0226 - val_accuracy: 0.8746 - val_loss: 0.8535\n",
      "Epoch 43/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9929 - loss: 0.0213 - val_accuracy: 0.8929 - val_loss: 0.8073\n",
      "Epoch 44/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9903 - loss: 0.0256 - val_accuracy: 0.8770 - val_loss: 0.8473\n",
      "Epoch 45/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9914 - loss: 0.0233 - val_accuracy: 0.8873 - val_loss: 0.8126\n",
      "Epoch 46/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9943 - loss: 0.0176 - val_accuracy: 0.8714 - val_loss: 0.8762\n",
      "Epoch 47/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9888 - loss: 0.0297 - val_accuracy: 0.8817 - val_loss: 0.8762\n",
      "Epoch 48/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9932 - loss: 0.0191 - val_accuracy: 0.8913 - val_loss: 0.8145\n",
      "Epoch 49/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9946 - loss: 0.0171 - val_accuracy: 0.8992 - val_loss: 0.8797\n",
      "Epoch 50/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9938 - loss: 0.0212 - val_accuracy: 0.8841 - val_loss: 0.8994\n",
      "Epoch 51/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9942 - loss: 0.0176 - val_accuracy: 0.8817 - val_loss: 0.8851\n",
      "Epoch 52/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9948 - loss: 0.0191 - val_accuracy: 0.8825 - val_loss: 0.8922\n",
      "Epoch 53/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9946 - loss: 0.0178 - val_accuracy: 0.8889 - val_loss: 0.8910\n",
      "Epoch 54/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9946 - loss: 0.0172 - val_accuracy: 0.8976 - val_loss: 0.8848\n",
      "Epoch 55/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9933 - loss: 0.0182 - val_accuracy: 0.8881 - val_loss: 0.8728\n",
      "Epoch 56/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9949 - loss: 0.0144 - val_accuracy: 0.8794 - val_loss: 0.9289\n",
      "Epoch 57/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9945 - loss: 0.0171 - val_accuracy: 0.8889 - val_loss: 0.9084\n",
      "Epoch 58/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9941 - loss: 0.0158 - val_accuracy: 0.9048 - val_loss: 0.8640\n",
      "Epoch 59/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9946 - loss: 0.0154 - val_accuracy: 0.8873 - val_loss: 0.8974\n",
      "Epoch 60/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9957 - loss: 0.0138 - val_accuracy: 0.9032 - val_loss: 0.9097\n",
      "Epoch 61/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9928 - loss: 0.0223 - val_accuracy: 0.8905 - val_loss: 0.8813\n",
      "Epoch 62/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9957 - loss: 0.0122 - val_accuracy: 0.8976 - val_loss: 0.8763\n",
      "Epoch 63/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9954 - loss: 0.0136 - val_accuracy: 0.8786 - val_loss: 0.9498\n",
      "Epoch 64/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9935 - loss: 0.0196 - val_accuracy: 0.8952 - val_loss: 0.8617\n",
      "Epoch 65/100\n",
      "432/432 - 2s - 4ms/step - accuracy: 0.9943 - loss: 0.0159 - val_accuracy: 0.8960 - val_loss: 0.8699\n",
      "Epoch 66/100\n",
      "432/432 - 2s - 5ms/step - accuracy: 0.9955 - loss: 0.0133 - val_accuracy: 0.8960 - val_loss: 0.9218\n",
      "Epoch 67/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9968 - loss: 0.0118 - val_accuracy: 0.8897 - val_loss: 0.9354\n",
      "Epoch 68/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9952 - loss: 0.0165 - val_accuracy: 0.8817 - val_loss: 0.9669\n",
      "Epoch 69/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9926 - loss: 0.0195 - val_accuracy: 0.8865 - val_loss: 0.9291\n",
      "Epoch 70/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9959 - loss: 0.0121 - val_accuracy: 0.8897 - val_loss: 0.9510\n",
      "Epoch 71/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9958 - loss: 0.0109 - val_accuracy: 0.8905 - val_loss: 0.9346\n",
      "Epoch 72/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9957 - loss: 0.0125 - val_accuracy: 0.8857 - val_loss: 1.0096\n",
      "Epoch 73/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9946 - loss: 0.0150 - val_accuracy: 0.8968 - val_loss: 0.9600\n",
      "Epoch 74/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9964 - loss: 0.0125 - val_accuracy: 0.8921 - val_loss: 0.9622\n",
      "Epoch 75/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9965 - loss: 0.0105 - val_accuracy: 0.8865 - val_loss: 0.9796\n",
      "Epoch 76/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9962 - loss: 0.0123 - val_accuracy: 0.8976 - val_loss: 0.9111\n",
      "Epoch 77/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9945 - loss: 0.0153 - val_accuracy: 0.8944 - val_loss: 0.9691\n",
      "Epoch 78/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9961 - loss: 0.0111 - val_accuracy: 0.8817 - val_loss: 0.9749\n",
      "Epoch 79/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9955 - loss: 0.0111 - val_accuracy: 0.8881 - val_loss: 0.9820\n",
      "Epoch 80/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9930 - loss: 0.0210 - val_accuracy: 0.8873 - val_loss: 0.9555\n",
      "Epoch 81/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9967 - loss: 0.0088 - val_accuracy: 0.8905 - val_loss: 0.9705\n",
      "Epoch 82/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9970 - loss: 0.0100 - val_accuracy: 0.8944 - val_loss: 0.9638\n",
      "Epoch 83/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9964 - loss: 0.0112 - val_accuracy: 0.8659 - val_loss: 1.0565\n",
      "Epoch 84/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9928 - loss: 0.0174 - val_accuracy: 0.8857 - val_loss: 0.9969\n",
      "Epoch 85/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9955 - loss: 0.0147 - val_accuracy: 0.8960 - val_loss: 0.9859\n",
      "Epoch 86/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9972 - loss: 0.0085 - val_accuracy: 0.9048 - val_loss: 0.9884\n",
      "Epoch 87/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9972 - loss: 0.0095 - val_accuracy: 0.8913 - val_loss: 1.0069\n",
      "Epoch 88/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9965 - loss: 0.0110 - val_accuracy: 0.8929 - val_loss: 1.0363\n",
      "Epoch 89/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9971 - loss: 0.0117 - val_accuracy: 0.8913 - val_loss: 1.0101\n",
      "Epoch 90/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9949 - loss: 0.0139 - val_accuracy: 0.8921 - val_loss: 1.0262\n",
      "Epoch 91/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9970 - loss: 0.0089 - val_accuracy: 0.8817 - val_loss: 1.0192\n",
      "Epoch 92/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9958 - loss: 0.0108 - val_accuracy: 0.8865 - val_loss: 1.0494\n",
      "Epoch 93/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9952 - loss: 0.0100 - val_accuracy: 0.8984 - val_loss: 1.0122\n",
      "Epoch 94/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9971 - loss: 0.0097 - val_accuracy: 0.8810 - val_loss: 1.0849\n",
      "Epoch 95/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9971 - loss: 0.0094 - val_accuracy: 0.8937 - val_loss: 1.0207\n",
      "Epoch 96/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9965 - loss: 0.0087 - val_accuracy: 0.8913 - val_loss: 1.0339\n",
      "Epoch 97/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9964 - loss: 0.0092 - val_accuracy: 0.8905 - val_loss: 1.0771\n",
      "Epoch 98/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9938 - loss: 0.0184 - val_accuracy: 0.8849 - val_loss: 1.0275\n",
      "Epoch 99/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9983 - loss: 0.0073 - val_accuracy: 0.8952 - val_loss: 1.0341\n",
      "Epoch 100/100\n",
      "432/432 - 1s - 3ms/step - accuracy: 0.9968 - loss: 0.0095 - val_accuracy: 0.8921 - val_loss: 0.9990\n",
      "test loss: 0.9981057643890381\n",
      "Test accuracy: 0.8896825313568115\n"
     ]
    }
   ],
   "source": [
    "# Feature column names\n",
    "last1year_features = []\n",
    "last2year_features = []\n",
    "last3year_features = []\n",
    "\n",
    "# Loop to build list of feature column names\n",
    "for i in range(1, 19):\n",
    "    last1year_features.append(f'X{i}_last1year')\n",
    "    last1year_features.append(f'X{i}_last1year_ycr')\n",
    "    last2year_features.append(f'X{i}_last2year')\n",
    "    last2year_features.append(f'X{i}_last2year_ycr')\n",
    "    last3year_features.append(f'X{i}_last3year')\n",
    "    last3year_features.append(f'X{i}_last3year_ycr')\n",
    "\n",
    "last1year_features.extend(['nyse_last1year', 'nasdaq_last1year', 'Division_encoded', 'MajorGroup_encoded'])\n",
    "last2year_features.extend(['nyse_last2year', 'nasdaq_last2year', 'Division_encoded', 'MajorGroup_encoded'])\n",
    "last3year_features.extend(['nyse_last3year', 'nasdaq_last3year', 'Division_encoded', 'MajorGroup_encoded'])\n",
    "\n",
    "# Define target column name\n",
    "target_column = 'status_label_encoded'\n",
    "\n",
    "# Extract features and target\n",
    "X_last1year = data_cleaned[last1year_features].values\n",
    "X_last2year = data_cleaned[last2year_features].values\n",
    "X_last3year = data_cleaned[last3year_features].values\n",
    "y = data_cleaned[target_column].values\n",
    "\n",
    "# Print data structure\n",
    "print(\"Shape of X_last1year:\", X_last1year.shape)\n",
    "print(\"Shape of X_last2year:\", X_last2year.shape)\n",
    "print(\"Shape of X_last3year:\", X_last3year.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Data Standardization\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the scaler\n",
    "scaler = StandardScaler()\n",
    "# Fit the scaler on the entire data set\n",
    "scaler.fit(np.concatenate((X_last1year, X_last2year, X_last3year,), axis=0))\n",
    "# Transform each year's data using the same scaler\n",
    "X_last1year_scaled = scaler.transform(X_last1year)\n",
    "X_last2year_scaled = scaler.transform(X_last2year)\n",
    "X_last3year_scaled = scaler.transform(X_last3year)\n",
    "\n",
    "# Reshape features to 3D arrays [samples, time steps, features]\n",
    "X_last1year_reshaped = np.reshape(X_last1year_scaled, (X_last1year_scaled.shape[0], 1, X_last1year_scaled.shape[1]))\n",
    "X_last2year_reshaped = np.reshape(X_last2year_scaled, (X_last2year_scaled.shape[0], 1, X_last2year_scaled.shape[1]))\n",
    "X_last3year_reshaped = np.reshape(X_last3year_scaled, (X_last3year_scaled.shape[0], 1, X_last3year_scaled.shape[1]))\n",
    "\n",
    "# Combine last1year and last2year features along the time step dimension\n",
    "X_combined_reshaped = np.concatenate((X_last3year_reshaped, X_last2year_reshaped, X_last1year_reshaped), axis=1)\n",
    "#First use data from the past two years (X_last3year_reshaped), then data from the past years \n",
    "\n",
    "# Print data structure\n",
    "print(\"Shape of X_last1year_scaled:\", X_last1year_scaled.shape)\n",
    "print(\"Shape of X_last2year_scaled:\", X_last2year_scaled.shape)\n",
    "print(\"Shape of X_last3year_scaled:\", X_last3year_scaled.shape)\n",
    "print(\"Shape of X_combined_reshaped:\", X_combined_reshaped.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_combined_reshaped, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42) # 0.8 * 0.25 = 0.2\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_val:\", X_val.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Flatten X_train\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "# Apply SMOTE only on the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_flat, y_train)\n",
    "print(\"Shape of X_train_resampled:\", X_train_resampled.shape)\n",
    "# Reshape resampled training data to match LSTM input shape\n",
    "X_train_resampled = X_train_resampled.reshape(-1, 3, X_train.shape[2])\n",
    "# Check the shape of resampled data and target variable\n",
    "print(\"Shape of X_train_resampled:\", X_train_resampled.shape)\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import LSTM, Dense, Dropout, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define LSTM model\n",
    "inputs = Input(shape=(3, X_train_resampled.shape[2]))  # (2, number of features) Accepts data with two time steps as input, and the first time step is the data of the past two years and the second time step is the data of the past year.\n",
    "lstm_layer = LSTM(100)(inputs)\n",
    "dropout_layer = Dropout(0.2)(lstm_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(dropout_layer)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output_layer)\n",
    "\n",
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_resampled, y_train_resampled, epochs=100, batch_size=16, validation_data=(X_val, y_val), verbose=2)\n",
    "\n",
    "## Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"test loss:\", loss)\n",
    "print(\"Test accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69807993-1318-489a-b3b3-7c05f4ba3e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Accuracy: 0.8896825396825396\n",
      "Recall: 0.2857142857142857\n",
      "Precision: 0.28865979381443296\n",
      "F1 Score: 0.28717948717948716\n",
      "Micro F1 Score: 0.8896825396825395\n",
      "Macro F1 Score: 0.613697270471464\n",
      "ROC AUC: 0.7741490744318381\n",
      "Confusion Matrix:\n",
      "[[1093   69]\n",
      " [  70   28]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6720ad-6776-4453-87c3-b823cc3c885e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea564635-c3db-48ed-900d-5a9e2a28d51a",
   "metadata": {},
   "source": [
    "### 1.3  Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a0c316f-8a6c-42ca-9d31-8aa5b926838f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_last1year: (6298, 40)\n",
      "Shape of X_last2year: (6298, 40)\n",
      "Shape of X_last3year: (6298, 40)\n",
      "Shape of y: (6298,)\n",
      "Shape of X_last1year_scaled: (6298, 40)\n",
      "Shape of X_last2year_scaled: (6298, 40)\n",
      "Shape of X_last3year_scaled: (6298, 40)\n",
      "Shape of X_combined_reshaped: (6298, 3, 40)\n",
      "Shape of X_train: (3778, 3, 40)\n",
      "Shape of X_val: (1260, 3, 40)\n",
      "Shape of X_test: (1260, 3, 40)\n",
      "Shape of X_train_resampled: (658, 120)\n",
      "Shape of X_train_resampled: (658, 3, 40)\n",
      "Epoch 1/100\n",
      "42/42 - 2s - 57ms/step - accuracy: 0.6596 - loss: 0.6398 - val_accuracy: 0.5675 - val_loss: 0.6853\n",
      "Epoch 2/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.7249 - loss: 0.5628 - val_accuracy: 0.6087 - val_loss: 0.6030\n",
      "Epoch 3/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.7310 - loss: 0.5320 - val_accuracy: 0.6040 - val_loss: 0.5877\n",
      "Epoch 4/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.7477 - loss: 0.5146 - val_accuracy: 0.6119 - val_loss: 0.5932\n",
      "Epoch 5/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.7401 - loss: 0.4993 - val_accuracy: 0.6183 - val_loss: 0.5840\n",
      "Epoch 6/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.7523 - loss: 0.4886 - val_accuracy: 0.6167 - val_loss: 0.5830\n",
      "Epoch 7/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.7690 - loss: 0.4775 - val_accuracy: 0.6230 - val_loss: 0.6389\n",
      "Epoch 8/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.7690 - loss: 0.4733 - val_accuracy: 0.6810 - val_loss: 0.5336\n",
      "Epoch 9/100\n",
      "42/42 - 0s - 9ms/step - accuracy: 0.7766 - loss: 0.4565 - val_accuracy: 0.6127 - val_loss: 0.6139\n",
      "Epoch 10/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.7766 - loss: 0.4491 - val_accuracy: 0.6341 - val_loss: 0.6029\n",
      "Epoch 11/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.7736 - loss: 0.4347 - val_accuracy: 0.6333 - val_loss: 0.6282\n",
      "Epoch 12/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.7979 - loss: 0.4293 - val_accuracy: 0.6429 - val_loss: 0.6561\n",
      "Epoch 13/100\n",
      "42/42 - 0s - 6ms/step - accuracy: 0.7888 - loss: 0.4213 - val_accuracy: 0.7032 - val_loss: 0.5526\n",
      "Epoch 14/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.8055 - loss: 0.4029 - val_accuracy: 0.6405 - val_loss: 0.6449\n",
      "Epoch 15/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.8207 - loss: 0.3980 - val_accuracy: 0.6865 - val_loss: 0.6133\n",
      "Epoch 16/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.8191 - loss: 0.3890 - val_accuracy: 0.7294 - val_loss: 0.5488\n",
      "Epoch 17/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.8267 - loss: 0.3840 - val_accuracy: 0.7079 - val_loss: 0.6043\n",
      "Epoch 18/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.8298 - loss: 0.3684 - val_accuracy: 0.7000 - val_loss: 0.6089\n",
      "Epoch 19/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.8359 - loss: 0.3643 - val_accuracy: 0.6778 - val_loss: 0.6742\n",
      "Epoch 20/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.8343 - loss: 0.3541 - val_accuracy: 0.7151 - val_loss: 0.6393\n",
      "Epoch 21/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.8389 - loss: 0.3455 - val_accuracy: 0.6817 - val_loss: 0.6731\n",
      "Epoch 22/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.8359 - loss: 0.3484 - val_accuracy: 0.6698 - val_loss: 0.7008\n",
      "Epoch 23/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.8587 - loss: 0.3279 - val_accuracy: 0.6992 - val_loss: 0.7039\n",
      "Epoch 24/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.8541 - loss: 0.3250 - val_accuracy: 0.6833 - val_loss: 0.7318\n",
      "Epoch 25/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.8465 - loss: 0.3197 - val_accuracy: 0.6587 - val_loss: 0.8043\n",
      "Epoch 26/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.8556 - loss: 0.3150 - val_accuracy: 0.6556 - val_loss: 0.8508\n",
      "Epoch 27/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.8526 - loss: 0.3071 - val_accuracy: 0.7222 - val_loss: 0.7066\n",
      "Epoch 28/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.8495 - loss: 0.3066 - val_accuracy: 0.7492 - val_loss: 0.6678\n",
      "Epoch 29/100\n",
      "42/42 - 0s - 9ms/step - accuracy: 0.8693 - loss: 0.2998 - val_accuracy: 0.7468 - val_loss: 0.6860\n",
      "Epoch 30/100\n",
      "42/42 - 1s - 16ms/step - accuracy: 0.8693 - loss: 0.2906 - val_accuracy: 0.7119 - val_loss: 0.7282\n",
      "Epoch 31/100\n",
      "42/42 - 0s - 9ms/step - accuracy: 0.8769 - loss: 0.2844 - val_accuracy: 0.6849 - val_loss: 0.8231\n",
      "Epoch 32/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.8830 - loss: 0.2826 - val_accuracy: 0.6571 - val_loss: 0.9270\n",
      "Epoch 33/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.8632 - loss: 0.2746 - val_accuracy: 0.7167 - val_loss: 0.7995\n",
      "Epoch 34/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.8799 - loss: 0.2664 - val_accuracy: 0.7127 - val_loss: 0.8212\n",
      "Epoch 35/100\n",
      "42/42 - 0s - 9ms/step - accuracy: 0.8830 - loss: 0.2613 - val_accuracy: 0.7024 - val_loss: 0.8501\n",
      "Epoch 36/100\n",
      "42/42 - 0s - 9ms/step - accuracy: 0.8860 - loss: 0.2522 - val_accuracy: 0.7405 - val_loss: 0.7637\n",
      "Epoch 37/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.8784 - loss: 0.2515 - val_accuracy: 0.6587 - val_loss: 1.0051\n",
      "Epoch 38/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.8906 - loss: 0.2398 - val_accuracy: 0.7214 - val_loss: 0.8779\n",
      "Epoch 39/100\n",
      "42/42 - 0s - 9ms/step - accuracy: 0.8875 - loss: 0.2393 - val_accuracy: 0.7270 - val_loss: 0.8479\n",
      "Epoch 40/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.8830 - loss: 0.2414 - val_accuracy: 0.7183 - val_loss: 0.8966\n",
      "Epoch 41/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.8845 - loss: 0.2380 - val_accuracy: 0.7373 - val_loss: 0.8411\n",
      "Epoch 42/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.8951 - loss: 0.2294 - val_accuracy: 0.7095 - val_loss: 0.8998\n",
      "Epoch 43/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9043 - loss: 0.2169 - val_accuracy: 0.7492 - val_loss: 0.8741\n",
      "Epoch 44/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9088 - loss: 0.2124 - val_accuracy: 0.7008 - val_loss: 1.0094\n",
      "Epoch 45/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9058 - loss: 0.2119 - val_accuracy: 0.6960 - val_loss: 1.0155\n",
      "Epoch 46/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9119 - loss: 0.2011 - val_accuracy: 0.6810 - val_loss: 1.1105\n",
      "Epoch 47/100\n",
      "42/42 - 0s - 9ms/step - accuracy: 0.9073 - loss: 0.2079 - val_accuracy: 0.7087 - val_loss: 1.0039\n",
      "Epoch 48/100\n",
      "42/42 - 0s - 9ms/step - accuracy: 0.9149 - loss: 0.1958 - val_accuracy: 0.6952 - val_loss: 1.0836\n",
      "Epoch 49/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.9119 - loss: 0.1971 - val_accuracy: 0.6944 - val_loss: 1.1567\n",
      "Epoch 50/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.9088 - loss: 0.1988 - val_accuracy: 0.6865 - val_loss: 1.0901\n",
      "Epoch 51/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.9119 - loss: 0.1810 - val_accuracy: 0.7254 - val_loss: 1.0303\n",
      "Epoch 52/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9331 - loss: 0.1760 - val_accuracy: 0.6944 - val_loss: 1.1842\n",
      "Epoch 53/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9210 - loss: 0.1749 - val_accuracy: 0.7230 - val_loss: 1.0689\n",
      "Epoch 54/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9149 - loss: 0.1657 - val_accuracy: 0.7119 - val_loss: 1.1328\n",
      "Epoch 55/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.9103 - loss: 0.1940 - val_accuracy: 0.6635 - val_loss: 1.2437\n",
      "Epoch 56/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9119 - loss: 0.1894 - val_accuracy: 0.7206 - val_loss: 1.1160\n",
      "Epoch 57/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9240 - loss: 0.1709 - val_accuracy: 0.6690 - val_loss: 1.1876\n",
      "Epoch 58/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.9255 - loss: 0.1625 - val_accuracy: 0.6754 - val_loss: 1.2607\n",
      "Epoch 59/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9422 - loss: 0.1455 - val_accuracy: 0.7000 - val_loss: 1.1406\n",
      "Epoch 60/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9468 - loss: 0.1475 - val_accuracy: 0.7333 - val_loss: 1.1236\n",
      "Epoch 61/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9255 - loss: 0.1541 - val_accuracy: 0.6984 - val_loss: 1.2224\n",
      "Epoch 62/100\n",
      "42/42 - 0s - 6ms/step - accuracy: 0.9407 - loss: 0.1392 - val_accuracy: 0.6548 - val_loss: 1.3930\n",
      "Epoch 63/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9498 - loss: 0.1342 - val_accuracy: 0.6857 - val_loss: 1.3180\n",
      "Epoch 64/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9468 - loss: 0.1367 - val_accuracy: 0.6937 - val_loss: 1.3509\n",
      "Epoch 65/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9498 - loss: 0.1206 - val_accuracy: 0.7381 - val_loss: 1.2038\n",
      "Epoch 66/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9468 - loss: 0.1234 - val_accuracy: 0.7754 - val_loss: 1.0293\n",
      "Epoch 67/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9483 - loss: 0.1222 - val_accuracy: 0.6976 - val_loss: 1.3581\n",
      "Epoch 68/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9498 - loss: 0.1238 - val_accuracy: 0.6905 - val_loss: 1.3762\n",
      "Epoch 69/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9590 - loss: 0.1129 - val_accuracy: 0.6992 - val_loss: 1.4007\n",
      "Epoch 70/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9574 - loss: 0.1076 - val_accuracy: 0.6881 - val_loss: 1.4430\n",
      "Epoch 71/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9559 - loss: 0.1068 - val_accuracy: 0.7095 - val_loss: 1.3256\n",
      "Epoch 72/100\n",
      "42/42 - 0s - 9ms/step - accuracy: 0.9559 - loss: 0.1138 - val_accuracy: 0.7254 - val_loss: 1.3062\n",
      "Epoch 73/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.9605 - loss: 0.1075 - val_accuracy: 0.6976 - val_loss: 1.4206\n",
      "Epoch 74/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.9590 - loss: 0.1008 - val_accuracy: 0.6667 - val_loss: 1.5099\n",
      "Epoch 75/100\n",
      "42/42 - 0s - 9ms/step - accuracy: 0.9590 - loss: 0.1122 - val_accuracy: 0.6738 - val_loss: 1.5639\n",
      "Epoch 76/100\n",
      "42/42 - 0s - 9ms/step - accuracy: 0.9590 - loss: 0.1018 - val_accuracy: 0.6619 - val_loss: 1.5773\n",
      "Epoch 77/100\n",
      "42/42 - 0s - 9ms/step - accuracy: 0.9620 - loss: 0.0915 - val_accuracy: 0.6937 - val_loss: 1.5008\n",
      "Epoch 78/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.9650 - loss: 0.0931 - val_accuracy: 0.6698 - val_loss: 1.6140\n",
      "Epoch 79/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.9681 - loss: 0.0854 - val_accuracy: 0.7341 - val_loss: 1.3880\n",
      "Epoch 80/100\n",
      "42/42 - 0s - 9ms/step - accuracy: 0.9711 - loss: 0.0800 - val_accuracy: 0.7103 - val_loss: 1.5182\n",
      "Epoch 81/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.9666 - loss: 0.0859 - val_accuracy: 0.7032 - val_loss: 1.5576\n",
      "Epoch 82/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.9711 - loss: 0.0801 - val_accuracy: 0.7437 - val_loss: 1.4439\n",
      "Epoch 83/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.9711 - loss: 0.0880 - val_accuracy: 0.6571 - val_loss: 1.8103\n",
      "Epoch 84/100\n",
      "42/42 - 0s - 9ms/step - accuracy: 0.9757 - loss: 0.0740 - val_accuracy: 0.6913 - val_loss: 1.6616\n",
      "Epoch 85/100\n",
      "42/42 - 0s - 8ms/step - accuracy: 0.9772 - loss: 0.0766 - val_accuracy: 0.6992 - val_loss: 1.7448\n",
      "Epoch 86/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9787 - loss: 0.0746 - val_accuracy: 0.6484 - val_loss: 1.8625\n",
      "Epoch 87/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9726 - loss: 0.0750 - val_accuracy: 0.7016 - val_loss: 1.7099\n",
      "Epoch 88/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9650 - loss: 0.0732 - val_accuracy: 0.6754 - val_loss: 1.7387\n",
      "Epoch 89/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9818 - loss: 0.0619 - val_accuracy: 0.6952 - val_loss: 1.7408\n",
      "Epoch 90/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9590 - loss: 0.1019 - val_accuracy: 0.6556 - val_loss: 1.8410\n",
      "Epoch 91/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9757 - loss: 0.0701 - val_accuracy: 0.7278 - val_loss: 1.5898\n",
      "Epoch 92/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9772 - loss: 0.0715 - val_accuracy: 0.6778 - val_loss: 1.7678\n",
      "Epoch 93/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9787 - loss: 0.0620 - val_accuracy: 0.7135 - val_loss: 1.6574\n",
      "Epoch 94/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9848 - loss: 0.0603 - val_accuracy: 0.7000 - val_loss: 1.7298\n",
      "Epoch 95/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9818 - loss: 0.0602 - val_accuracy: 0.7286 - val_loss: 1.6330\n",
      "Epoch 96/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9726 - loss: 0.0748 - val_accuracy: 0.6738 - val_loss: 1.8212\n",
      "Epoch 97/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9772 - loss: 0.0575 - val_accuracy: 0.6841 - val_loss: 1.8103\n",
      "Epoch 98/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9802 - loss: 0.0534 - val_accuracy: 0.7167 - val_loss: 1.6991\n",
      "Epoch 99/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9787 - loss: 0.0595 - val_accuracy: 0.6825 - val_loss: 1.8593\n",
      "Epoch 100/100\n",
      "42/42 - 0s - 7ms/step - accuracy: 0.9878 - loss: 0.0454 - val_accuracy: 0.6881 - val_loss: 1.8334\n",
      "test loss: 1.7795723676681519\n",
      "Test accuracy: 0.7182539701461792\n"
     ]
    }
   ],
   "source": [
    "# Feature column names\n",
    "last1year_features = []\n",
    "last2year_features = []\n",
    "last3year_features = []\n",
    "\n",
    "# Loop to build list of feature column names\n",
    "for i in range(1, 19):\n",
    "    last1year_features.append(f'X{i}_last1year')\n",
    "    last1year_features.append(f'X{i}_last1year_ycr')\n",
    "    last2year_features.append(f'X{i}_last2year')\n",
    "    last2year_features.append(f'X{i}_last2year_ycr')\n",
    "    last3year_features.append(f'X{i}_last3year')\n",
    "    last3year_features.append(f'X{i}_last3year_ycr')\n",
    "\n",
    "last1year_features.extend(['nyse_last1year', 'nasdaq_last1year', 'Division_encoded', 'MajorGroup_encoded'])\n",
    "last2year_features.extend(['nyse_last2year', 'nasdaq_last2year', 'Division_encoded', 'MajorGroup_encoded'])\n",
    "last3year_features.extend(['nyse_last3year', 'nasdaq_last3year', 'Division_encoded', 'MajorGroup_encoded'])\n",
    "\n",
    "# Define target column name\n",
    "target_column = 'status_label_encoded'\n",
    "\n",
    "# Extract features and target\n",
    "X_last1year = data_cleaned[last1year_features].values\n",
    "X_last2year = data_cleaned[last2year_features].values\n",
    "X_last3year = data_cleaned[last3year_features].values\n",
    "y = data_cleaned[target_column].values\n",
    "\n",
    "# Print data structure\n",
    "print(\"Shape of X_last1year:\", X_last1year.shape)\n",
    "print(\"Shape of X_last2year:\", X_last2year.shape)\n",
    "print(\"Shape of X_last3year:\", X_last3year.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Data Standardization\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the scaler\n",
    "scaler = StandardScaler()\n",
    "# Fit the scaler on the entire data set\n",
    "scaler.fit(np.concatenate((X_last1year, X_last2year, X_last3year,), axis=0))\n",
    "# Transform each year's data using the same scaler\n",
    "X_last1year_scaled = scaler.transform(X_last1year)\n",
    "X_last2year_scaled = scaler.transform(X_last2year)\n",
    "X_last3year_scaled = scaler.transform(X_last3year)\n",
    "\n",
    "# Reshape features to 3D arrays [samples, time steps, features]\n",
    "X_last1year_reshaped = np.reshape(X_last1year_scaled, (X_last1year_scaled.shape[0], 1, X_last1year_scaled.shape[1]))\n",
    "X_last2year_reshaped = np.reshape(X_last2year_scaled, (X_last2year_scaled.shape[0], 1, X_last2year_scaled.shape[1]))\n",
    "X_last3year_reshaped = np.reshape(X_last3year_scaled, (X_last3year_scaled.shape[0], 1, X_last3year_scaled.shape[1]))\n",
    "\n",
    "# Combine last1year and last2year features along the time step dimension\n",
    "X_combined_reshaped = np.concatenate((X_last3year_reshaped, X_last2year_reshaped, X_last1year_reshaped), axis=1)\n",
    "#First use data from the past two years (X_last3year_reshaped), then data from the past years \n",
    "\n",
    "# Print data structure\n",
    "print(\"Shape of X_last1year_scaled:\", X_last1year_scaled.shape)\n",
    "print(\"Shape of X_last2year_scaled:\", X_last2year_scaled.shape)\n",
    "print(\"Shape of X_last3year_scaled:\", X_last3year_scaled.shape)\n",
    "print(\"Shape of X_combined_reshaped:\", X_combined_reshaped.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_combined_reshaped, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42) # 0.8 * 0.25 = 0.2\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_val:\", X_val.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Flatten X_train\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "# Apply undersampling only on the training set\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train_flat, y_train)\n",
    "print(\"Shape of X_train_resampled:\", X_train_resampled.shape)\n",
    "# Reshape resampled training data to match LSTM input shape\n",
    "X_train_resampled = X_train_resampled.reshape(-1, 3, X_train.shape[2])\n",
    "# Check the shape of resampled data and target variable\n",
    "print(\"Shape of X_train_resampled:\", X_train_resampled.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import LSTM, Dense, Dropout, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define LSTM model\n",
    "inputs = Input(shape=(3, X_train_resampled.shape[2]))  # (2, number of features) Accepts data with two time steps as input, and the first time step is the data of the past two years and the second time step is the data of the past year.\n",
    "lstm_layer = LSTM(100)(inputs)\n",
    "dropout_layer = Dropout(0.2)(lstm_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(dropout_layer)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output_layer)\n",
    "\n",
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_resampled, y_train_resampled, epochs=100, batch_size=16, validation_data=(X_val, y_val), verbose=2)\n",
    "\n",
    "## Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"test loss:\", loss)\n",
    "print(\"Test accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07b5fd96-d19e-44b0-8413-e6593829a963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Accuracy: 0.7182539682539683\n",
      "Recall: 0.6326530612244898\n",
      "Precision: 0.16272965879265092\n",
      "F1 Score: 0.2588726513569937\n",
      "Micro F1 Score: 0.7182539682539683\n",
      "Macro F1 Score: 0.5424691527240628\n",
      "ROC AUC: 0.7575828093715972\n",
      "Confusion Matrix:\n",
      "[[843 319]\n",
      " [ 36  62]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f618dde2-f7d8-41d2-a0fb-7b9a656d3721",
   "metadata": {},
   "source": [
    "## undersampling, CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81d37288-6e3b-491f-8e23-5ebb4af8c83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_last1year: (6298, 40)\n",
      "Shape of X_last2year: (6298, 40)\n",
      "Shape of X_last3year: (6298, 40)\n",
      "Shape of y: (6298,)\n",
      "Shape of X_last1year_scaled: (6298, 40)\n",
      "Shape of X_last2year_scaled: (6298, 40)\n",
      "Shape of X_last3year_scaled: (6298, 40)\n",
      "Shape of X_combined_reshaped: (6298, 3, 40)\n",
      "Shape of X_train: (3778, 3, 40)\n",
      "Shape of X_val: (1260, 3, 40)\n",
      "Shape of X_test: (1260, 3, 40)\n",
      "Shape of X_train_resampled: (658, 120)\n",
      "Shape of X_train_resampled: (658, 3, 40)\n",
      "Shape of flattened_layer: (None, 1344)\n",
      "Epoch 1/100\n",
      "42/42 - 3s - 78ms/step - accuracy: 0.6474 - loss: 0.6332 - val_accuracy: 0.5984 - val_loss: 0.6930\n",
      "Epoch 2/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.7128 - loss: 0.5597 - val_accuracy: 0.7095 - val_loss: 0.5123\n",
      "Epoch 3/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.7204 - loss: 0.5348 - val_accuracy: 0.7770 - val_loss: 0.4189\n",
      "Epoch 4/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.7052 - loss: 0.5367 - val_accuracy: 0.6270 - val_loss: 0.5857\n",
      "Epoch 5/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.7447 - loss: 0.4984 - val_accuracy: 0.6357 - val_loss: 0.5826\n",
      "Epoch 6/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.7462 - loss: 0.4883 - val_accuracy: 0.5230 - val_loss: 0.7985\n",
      "Epoch 7/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.7508 - loss: 0.4777 - val_accuracy: 0.6365 - val_loss: 0.5805\n",
      "Epoch 8/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.7872 - loss: 0.4498 - val_accuracy: 0.7254 - val_loss: 0.5070\n",
      "Epoch 9/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.7827 - loss: 0.4398 - val_accuracy: 0.6468 - val_loss: 0.6187\n",
      "Epoch 10/100\n",
      "42/42 - 1s - 13ms/step - accuracy: 0.7872 - loss: 0.4365 - val_accuracy: 0.7000 - val_loss: 0.5681\n",
      "Epoch 11/100\n",
      "42/42 - 1s - 12ms/step - accuracy: 0.8070 - loss: 0.4095 - val_accuracy: 0.6405 - val_loss: 0.6661\n",
      "Epoch 12/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.7979 - loss: 0.4048 - val_accuracy: 0.6603 - val_loss: 0.6747\n",
      "Epoch 13/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.8252 - loss: 0.3863 - val_accuracy: 0.7159 - val_loss: 0.6101\n",
      "Epoch 14/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.8146 - loss: 0.3882 - val_accuracy: 0.7643 - val_loss: 0.5162\n",
      "Epoch 15/100\n",
      "42/42 - 1s - 13ms/step - accuracy: 0.8207 - loss: 0.3788 - val_accuracy: 0.7405 - val_loss: 0.5622\n",
      "Epoch 16/100\n",
      "42/42 - 0s - 12ms/step - accuracy: 0.8131 - loss: 0.3657 - val_accuracy: 0.5429 - val_loss: 1.1087\n",
      "Epoch 17/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.8389 - loss: 0.3536 - val_accuracy: 0.7675 - val_loss: 0.5426\n",
      "Epoch 18/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.8495 - loss: 0.3393 - val_accuracy: 0.8127 - val_loss: 0.4601\n",
      "Epoch 19/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.8435 - loss: 0.3240 - val_accuracy: 0.5802 - val_loss: 1.1956\n",
      "Epoch 20/100\n",
      "42/42 - 1s - 12ms/step - accuracy: 0.8541 - loss: 0.3192 - val_accuracy: 0.7032 - val_loss: 0.7499\n",
      "Epoch 21/100\n",
      "42/42 - 1s - 13ms/step - accuracy: 0.8647 - loss: 0.2971 - val_accuracy: 0.6429 - val_loss: 1.0569\n",
      "Epoch 22/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.8815 - loss: 0.2952 - val_accuracy: 0.6627 - val_loss: 0.9778\n",
      "Epoch 23/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.8602 - loss: 0.2873 - val_accuracy: 0.7540 - val_loss: 0.7274\n",
      "Epoch 24/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.8769 - loss: 0.2832 - val_accuracy: 0.5794 - val_loss: 1.2016\n",
      "Epoch 25/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.8632 - loss: 0.2880 - val_accuracy: 0.6270 - val_loss: 1.0976\n",
      "Epoch 26/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.8708 - loss: 0.2649 - val_accuracy: 0.7294 - val_loss: 0.7601\n",
      "Epoch 27/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.8860 - loss: 0.2520 - val_accuracy: 0.6151 - val_loss: 1.0856\n",
      "Epoch 28/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.8860 - loss: 0.2507 - val_accuracy: 0.6881 - val_loss: 0.8835\n",
      "Epoch 29/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.8921 - loss: 0.2324 - val_accuracy: 0.6556 - val_loss: 1.0716\n",
      "Epoch 30/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9012 - loss: 0.2446 - val_accuracy: 0.6762 - val_loss: 1.0768\n",
      "Epoch 31/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9119 - loss: 0.2105 - val_accuracy: 0.6937 - val_loss: 1.0310\n",
      "Epoch 32/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9286 - loss: 0.1909 - val_accuracy: 0.6119 - val_loss: 1.4370\n",
      "Epoch 33/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9225 - loss: 0.1877 - val_accuracy: 0.6881 - val_loss: 1.0858\n",
      "Epoch 34/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9195 - loss: 0.1912 - val_accuracy: 0.7302 - val_loss: 0.9587\n",
      "Epoch 35/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9043 - loss: 0.2173 - val_accuracy: 0.5667 - val_loss: 1.5802\n",
      "Epoch 36/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9179 - loss: 0.1915 - val_accuracy: 0.6579 - val_loss: 1.2181\n",
      "Epoch 37/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9316 - loss: 0.1706 - val_accuracy: 0.7762 - val_loss: 0.8341\n",
      "Epoch 38/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9331 - loss: 0.1568 - val_accuracy: 0.6032 - val_loss: 1.7240\n",
      "Epoch 39/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9483 - loss: 0.1498 - val_accuracy: 0.6746 - val_loss: 1.2996\n",
      "Epoch 40/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9422 - loss: 0.1347 - val_accuracy: 0.7492 - val_loss: 1.0367\n",
      "Epoch 41/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9529 - loss: 0.1326 - val_accuracy: 0.6310 - val_loss: 1.6328\n",
      "Epoch 42/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9590 - loss: 0.1132 - val_accuracy: 0.7444 - val_loss: 1.2386\n",
      "Epoch 43/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9498 - loss: 0.1230 - val_accuracy: 0.7040 - val_loss: 1.3533\n",
      "Epoch 44/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9453 - loss: 0.1385 - val_accuracy: 0.7135 - val_loss: 1.3212\n",
      "Epoch 45/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9605 - loss: 0.1075 - val_accuracy: 0.6722 - val_loss: 1.5220\n",
      "Epoch 46/100\n",
      "42/42 - 1s - 13ms/step - accuracy: 0.9620 - loss: 0.1024 - val_accuracy: 0.7071 - val_loss: 1.3715\n",
      "Epoch 47/100\n",
      "42/42 - 1s - 13ms/step - accuracy: 0.9635 - loss: 0.0983 - val_accuracy: 0.6198 - val_loss: 2.0730\n",
      "Epoch 48/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9590 - loss: 0.1056 - val_accuracy: 0.6992 - val_loss: 1.5596\n",
      "Epoch 49/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9681 - loss: 0.0860 - val_accuracy: 0.5683 - val_loss: 2.2863\n",
      "Epoch 50/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9574 - loss: 0.0988 - val_accuracy: 0.7675 - val_loss: 1.2561\n",
      "Epoch 51/100\n",
      "42/42 - 1s - 13ms/step - accuracy: 0.9696 - loss: 0.0822 - val_accuracy: 0.6413 - val_loss: 2.0937\n",
      "Epoch 52/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9666 - loss: 0.0893 - val_accuracy: 0.6357 - val_loss: 2.1166\n",
      "Epoch 53/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9696 - loss: 0.0812 - val_accuracy: 0.6960 - val_loss: 1.7694\n",
      "Epoch 54/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9681 - loss: 0.0797 - val_accuracy: 0.6627 - val_loss: 2.0045\n",
      "Epoch 55/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9620 - loss: 0.0928 - val_accuracy: 0.6683 - val_loss: 1.8242\n",
      "Epoch 56/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9772 - loss: 0.0656 - val_accuracy: 0.6508 - val_loss: 2.0737\n",
      "Epoch 57/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9772 - loss: 0.0643 - val_accuracy: 0.6310 - val_loss: 2.2601\n",
      "Epoch 58/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9711 - loss: 0.0625 - val_accuracy: 0.6500 - val_loss: 2.1125\n",
      "Epoch 59/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9878 - loss: 0.0488 - val_accuracy: 0.7071 - val_loss: 1.7898\n",
      "Epoch 60/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9863 - loss: 0.0515 - val_accuracy: 0.6944 - val_loss: 1.9157\n",
      "Epoch 61/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9848 - loss: 0.0455 - val_accuracy: 0.6833 - val_loss: 2.0338\n",
      "Epoch 62/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9848 - loss: 0.0458 - val_accuracy: 0.7056 - val_loss: 1.8691\n",
      "Epoch 63/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9848 - loss: 0.0465 - val_accuracy: 0.6968 - val_loss: 1.9532\n",
      "Epoch 64/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9818 - loss: 0.0432 - val_accuracy: 0.6833 - val_loss: 2.0092\n",
      "Epoch 65/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9894 - loss: 0.0390 - val_accuracy: 0.7167 - val_loss: 1.9191\n",
      "Epoch 66/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9818 - loss: 0.0440 - val_accuracy: 0.6548 - val_loss: 2.4309\n",
      "Epoch 67/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9924 - loss: 0.0364 - val_accuracy: 0.7071 - val_loss: 2.0235\n",
      "Epoch 68/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9909 - loss: 0.0340 - val_accuracy: 0.6627 - val_loss: 2.3583\n",
      "Epoch 69/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9894 - loss: 0.0379 - val_accuracy: 0.7143 - val_loss: 1.8786\n",
      "Epoch 70/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9863 - loss: 0.0401 - val_accuracy: 0.6556 - val_loss: 2.5622\n",
      "Epoch 71/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.8936 - loss: 0.2996 - val_accuracy: 0.6675 - val_loss: 1.5907\n",
      "Epoch 72/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9544 - loss: 0.1200 - val_accuracy: 0.6127 - val_loss: 1.9430\n",
      "Epoch 73/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9772 - loss: 0.0691 - val_accuracy: 0.6817 - val_loss: 1.6184\n",
      "Epoch 74/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9909 - loss: 0.0410 - val_accuracy: 0.6857 - val_loss: 1.8545\n",
      "Epoch 75/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9924 - loss: 0.0337 - val_accuracy: 0.6992 - val_loss: 1.7872\n",
      "Epoch 76/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9894 - loss: 0.0341 - val_accuracy: 0.6714 - val_loss: 2.0195\n",
      "Epoch 77/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9909 - loss: 0.0295 - val_accuracy: 0.6762 - val_loss: 2.1222\n",
      "Epoch 78/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9924 - loss: 0.0286 - val_accuracy: 0.6587 - val_loss: 2.3616\n",
      "Epoch 79/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9818 - loss: 0.0429 - val_accuracy: 0.7071 - val_loss: 1.8790\n",
      "Epoch 80/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9909 - loss: 0.0292 - val_accuracy: 0.6825 - val_loss: 2.0369\n",
      "Epoch 81/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9894 - loss: 0.0297 - val_accuracy: 0.6794 - val_loss: 2.1076\n",
      "Epoch 82/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9909 - loss: 0.0348 - val_accuracy: 0.7143 - val_loss: 1.8085\n",
      "Epoch 83/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9833 - loss: 0.0365 - val_accuracy: 0.6921 - val_loss: 2.1876\n",
      "Epoch 84/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9939 - loss: 0.0260 - val_accuracy: 0.6810 - val_loss: 2.1458\n",
      "Epoch 85/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9894 - loss: 0.0308 - val_accuracy: 0.6452 - val_loss: 2.4804\n",
      "Epoch 86/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9954 - loss: 0.0290 - val_accuracy: 0.6944 - val_loss: 2.1307\n",
      "Epoch 87/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9924 - loss: 0.0257 - val_accuracy: 0.6810 - val_loss: 2.3767\n",
      "Epoch 88/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9939 - loss: 0.0249 - val_accuracy: 0.6937 - val_loss: 2.3467\n",
      "Epoch 89/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9924 - loss: 0.0250 - val_accuracy: 0.6944 - val_loss: 2.2982\n",
      "Epoch 90/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9924 - loss: 0.0226 - val_accuracy: 0.6944 - val_loss: 2.2661\n",
      "Epoch 91/100\n",
      "42/42 - 1s - 13ms/step - accuracy: 0.9924 - loss: 0.0199 - val_accuracy: 0.7063 - val_loss: 2.1871\n",
      "Epoch 92/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9894 - loss: 0.0253 - val_accuracy: 0.6754 - val_loss: 2.4869\n",
      "Epoch 93/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9939 - loss: 0.0281 - val_accuracy: 0.5944 - val_loss: 3.2991\n",
      "Epoch 94/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9772 - loss: 0.0789 - val_accuracy: 0.6873 - val_loss: 2.2150\n",
      "Epoch 95/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9757 - loss: 0.0564 - val_accuracy: 0.7048 - val_loss: 1.9405\n",
      "Epoch 96/100\n",
      "42/42 - 0s - 11ms/step - accuracy: 0.9909 - loss: 0.0243 - val_accuracy: 0.6714 - val_loss: 2.4439\n",
      "Epoch 97/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9954 - loss: 0.0203 - val_accuracy: 0.7119 - val_loss: 2.1457\n",
      "Epoch 98/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9909 - loss: 0.0276 - val_accuracy: 0.7016 - val_loss: 2.1687\n",
      "Epoch 99/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9909 - loss: 0.0256 - val_accuracy: 0.6595 - val_loss: 2.5456\n",
      "Epoch 100/100\n",
      "42/42 - 0s - 10ms/step - accuracy: 0.9909 - loss: 0.0266 - val_accuracy: 0.6317 - val_loss: 2.7368\n",
      "test loss: 2.6559009552001953\n",
      "Test accuracy: 0.644444465637207\n"
     ]
    }
   ],
   "source": [
    "# Feature column names\n",
    "last1year_features = []\n",
    "last2year_features = []\n",
    "last3year_features = []\n",
    "\n",
    "# Loop to build list of feature column names\n",
    "for i in range(1, 19):\n",
    "    last1year_features.append(f'X{i}_last1year')\n",
    "    last1year_features.append(f'X{i}_last1year_ycr')\n",
    "    last2year_features.append(f'X{i}_last2year')\n",
    "    last2year_features.append(f'X{i}_last2year_ycr')\n",
    "    last3year_features.append(f'X{i}_last3year')\n",
    "    last3year_features.append(f'X{i}_last3year_ycr')\n",
    "\n",
    "last1year_features.extend(['nyse_last1year', 'nasdaq_last1year', 'Division_encoded', 'MajorGroup_encoded'])\n",
    "last2year_features.extend(['nyse_last2year', 'nasdaq_last2year', 'Division_encoded', 'MajorGroup_encoded'])\n",
    "last3year_features.extend(['nyse_last3year', 'nasdaq_last3year', 'Division_encoded', 'MajorGroup_encoded'])\n",
    "\n",
    "# Define target column name\n",
    "target_column = 'status_label_encoded'\n",
    "\n",
    "# Extract features and target\n",
    "X_last1year = data_cleaned[last1year_features].values\n",
    "X_last2year = data_cleaned[last2year_features].values\n",
    "X_last3year = data_cleaned[last3year_features].values\n",
    "y = data_cleaned[target_column].values\n",
    "\n",
    "# Print data structure\n",
    "print(\"Shape of X_last1year:\", X_last1year.shape)\n",
    "print(\"Shape of X_last2year:\", X_last2year.shape)\n",
    "print(\"Shape of X_last3year:\", X_last3year.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Data Standardization\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the scaler\n",
    "scaler = StandardScaler()\n",
    "# Fit the scaler on the entire data set\n",
    "scaler.fit(np.concatenate((X_last1year, X_last2year, X_last3year,), axis=0))\n",
    "# Transform each year's data using the same scaler\n",
    "X_last1year_scaled = scaler.transform(X_last1year)\n",
    "X_last2year_scaled = scaler.transform(X_last2year)\n",
    "X_last3year_scaled = scaler.transform(X_last3year)\n",
    "\n",
    "# Reshape features to 3D arrays [samples, time steps, features]\n",
    "X_last1year_reshaped = np.reshape(X_last1year_scaled, (X_last1year_scaled.shape[0], 1, X_last1year_scaled.shape[1]))\n",
    "X_last2year_reshaped = np.reshape(X_last2year_scaled, (X_last2year_scaled.shape[0], 1, X_last2year_scaled.shape[1]))\n",
    "X_last3year_reshaped = np.reshape(X_last3year_scaled, (X_last3year_scaled.shape[0], 1, X_last3year_scaled.shape[1]))\n",
    "\n",
    "# Combine last1year and last2year features along the time step dimension\n",
    "X_combined_reshaped = np.concatenate((X_last3year_reshaped, X_last2year_reshaped, X_last1year_reshaped), axis=1)\n",
    "#First use data from the past two years (X_last3year_reshaped), then data from the past years \n",
    "\n",
    "# Print data structure\n",
    "print(\"Shape of X_last1year_scaled:\", X_last1year_scaled.shape)\n",
    "print(\"Shape of X_last2year_scaled:\", X_last2year_scaled.shape)\n",
    "print(\"Shape of X_last3year_scaled:\", X_last3year_scaled.shape)\n",
    "print(\"Shape of X_combined_reshaped:\", X_combined_reshaped.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_combined_reshaped, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42) # 0.8 * 0.25 = 0.2\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_val:\", X_val.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Flatten X_train\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "# Apply undersampling only on the training set\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train_flat, y_train)\n",
    "print(\"Shape of X_train_resampled:\", X_train_resampled.shape)\n",
    "# Reshape resampled training data to match LSTM input shape\n",
    "X_train_resampled = X_train_resampled.reshape(-1, 3, X_train.shape[2])\n",
    "# Check the shape of resampled data and target variable\n",
    "print(\"Shape of X_train_resampled:\", X_train_resampled.shape)\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import LSTM, Dense, Dropout, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Reshape, Conv1D, MaxPooling1D, Flatten, ZeroPadding1D\n",
    "\n",
    "\n",
    "\n",
    "#Define input layer\n",
    "inputs = Input(shape=(3, X_train_resampled.shape[2]))\n",
    "# Reshape input to fit Conv1D layer\n",
    "inputs_reshaped = Reshape((X_train_resampled.shape[2], 3))(inputs)  \n",
    "# Define CNN-LSTM model\n",
    "cnn_layer = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs_reshaped)\n",
    "# Add Padding1D layer\n",
    "padded_layer = ZeroPadding1D(padding=2)(cnn_layer)  #Consider flatten being divisible by the LSTM time step, so add padding\n",
    "pooling_layer = MaxPooling1D(pool_size=2)(padded_layer)\n",
    "flattened_layer = Flatten()(pooling_layer)\n",
    "print(\"Shape of flattened_layer:\", flattened_layer.shape)\n",
    "reshaped_layer = Reshape((3, -1))(flattened_layer)  # Reshape the output to fit LSTM input  #The input shape expected by the LSTM layer is (timesteps, features)\n",
    "lstm_layer = LSTM(100)(reshaped_layer)   \n",
    "dropout_layer = Dropout(0.2)(lstm_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(dropout_layer)\n",
    "# Define the model\n",
    "model = Model(inputs=inputs, outputs=output_layer)\n",
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_resampled, y_train_resampled, epochs=100, batch_size=16, validation_data=(X_val, y_val), verbose=2)\n",
    "\n",
    "## Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"test loss:\", loss)\n",
    "print(\"Test accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38575709-80fb-4ec0-9557-a6c7f222b747",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "Accuracy: 0.6444444444444445\n",
      "Recall: 0.6938775510204082\n",
      "Precision: 0.13991769547325103\n",
      "F1 Score: 0.23287671232876714\n",
      "Micro F1 Score: 0.6444444444444445\n",
      "Macro F1 Score: 0.5007358768255407\n",
      "ROC AUC: 0.7377586146334609\n",
      "Confusion Matrix:\n",
      "[[744 418]\n",
      " [ 30  68]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e284f96-58bd-45f1-9206-6f27f866aa2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cb1e02-96ee-4d91-bfba-e4524663b949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76a68fa-dc0d-4cb3-8d15-dc35763e04b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
