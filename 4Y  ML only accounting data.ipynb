{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d162b6bb-04be-41c3-94af-44ab59e6500d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00c0043-c7ca-4492-ad2f-cced9d6fae30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2e3631-6704-4cac-8a49-88743235ff8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in 'company_name' column: 8971\n",
      "Number of unique values in 'status_label' column: 2\n",
      "Number of unique values in 'Division' column: 10\n",
      "Number of unique values in 'MajorGroup' column: 73\n",
      "Number of unique values in 'last_year' column: 20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data set\n",
    "data = pd.read_csv(\"new_df_selected4_last4years_adjusted.csv\")\n",
    "\n",
    "unique_company_names = data['company_name'].nunique()\n",
    "unique_status_labels = data['status_label'].nunique()\n",
    "unique_divisions = data['Division'].nunique()\n",
    "unique_majorgroup = data['MajorGroup'].nunique()\n",
    "unique_last_year = data['last_year'].nunique()\n",
    "\n",
    "print(\"Number of unique values in 'company_name' column:\", unique_company_names)\n",
    "print(\"Number of unique values in 'status_label' column:\", unique_status_labels)\n",
    "print(\"Number of unique values in 'Division' column:\", unique_divisions)\n",
    "print(\"Number of unique values in 'MajorGroup' column:\", unique_majorgroup)\n",
    "print(\"Number of unique values in 'last_year' column:\", unique_last_year)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263fa8e8-cf02-4f9e-a23d-74af29abb22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0552208d-295c-4128-90b8-ed6e4d3a1494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8971 entries, 0 to 8970\n",
      "Columns: 157 entries, company_name to nasdaq_last4year\n",
      "dtypes: float64(153), int64(1), object(3)\n",
      "memory usage: 10.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc4a5663-66c6-4f87-84bb-ff9ab875eba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  company_name status_label Division  MajorGroup  last_year  X1_last1year  \\\n",
      "0          C_1        alive        D          37     2017.0         942.7   \n",
      "1          C_2        alive        D          36     2010.0        1107.7   \n",
      "2          C_3        alive        D          38     2008.0       12686.0   \n",
      "3          C_4        alive        D          28     2007.0      581502.0   \n",
      "4          C_5        alive        D          35     1999.0       28957.0   \n",
      "\n",
      "   X1_last2year  X1_last3year  X1_last4year  X2_last1year  ...  \\\n",
      "0         888.5         873.1         954.1       1524.70  ...   \n",
      "1         900.2        1077.4        1008.2       1474.50  ...   \n",
      "2       13454.0       13582.0        7726.0      21401.00  ...   \n",
      "3      353541.0     1037047.0      672072.0    1288165.00  ...   \n",
      "4           NaN           NaN           NaN         42.21  ...   \n",
      "\n",
      "   nyse_last3year  nyse_last4year  nasdaq_last1year  nasdaq_last2year  \\\n",
      "0    10606.906738    10699.956624       6293.024211       5015.926717   \n",
      "1     8001.502441     9685.001790       2333.908345       1856.529999   \n",
      "2     8434.441610     7364.758301       2148.948334       2587.587504   \n",
      "3     7364.758301     6645.525065       2587.587504       2278.996664   \n",
      "4             NaN             NaN       2787.559998               NaN   \n",
      "\n",
      "   nasdaq_last3year  nasdaq_last4year  company_name_encoded  Division_encoded  \\\n",
      "0       4932.729126       4414.850057                     0                 3   \n",
      "1       2148.948334       2587.587504                  1111                 3   \n",
      "2       2278.996664       2100.603343                  2222                 3   \n",
      "3       2100.603343       1992.867482                  3333                 3   \n",
      "4               NaN               NaN                  4444                 3   \n",
      "\n",
      "   MajorGroup_encoded  status_label_encoded  \n",
      "0                  29                     0  \n",
      "1                  28                     0  \n",
      "2                  30                     0  \n",
      "3                  20                     0  \n",
      "4                  27                     0  \n",
      "\n",
      "[5 rows x 161 columns]\n"
     ]
    }
   ],
   "source": [
    "# Encoding non-numeric columns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "# Label-encode the company_name column\n",
    "data['company_name_encoded'] = label_encoder.fit_transform(data['company_name'])\n",
    "\n",
    "\n",
    "# Label-encode the Division column\n",
    "data['Division_encoded'] = label_encoder.fit_transform(data['Division'])\n",
    "\n",
    "# Label-encode MajorGroup columns\n",
    "data['MajorGroup_encoded'] = label_encoder.fit_transform(data['MajorGroup'])\n",
    "#When using label encoding for feature encoding, the sequential relationship between categories will not be introduced and will not have an impact on prediction.\n",
    "\n",
    "# Encode the label of the status_label column\n",
    "data['status_label_encoded'] = label_encoder.fit_transform(data['status_label'])\n",
    "#With only two categories, it may be simpler and more appropriate to use label encoding as it maps the categories to 0 and 1, suitable for use in tree-based models. \n",
    "#If use one-hot encoding, a new column will be generated\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1f286d3-0047-4da4-90dc-dd63a2e84a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8971 entries, 0 to 8970\n",
      "Columns: 161 entries, company_name to status_label_encoded\n",
      "dtypes: float64(153), int32(3), int64(2), object(3)\n",
      "memory usage: 10.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "374fe89d-42d2-472f-8724-dcc6f06dff33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8971, 161)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b45588-522a-4d3c-8509-9749f7d3c4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in 'company_name_encoded' column: 8971\n",
      "Number of unique values in 'status_label_encoded' column: 2\n",
      "Number of unique values in 'Division_encoded' column: 10\n",
      "Number of unique values in 'MajorGroup_encoded' column: 73\n"
     ]
    }
   ],
   "source": [
    "unique_company_names = data['company_name_encoded'].nunique()\n",
    "unique_status_labels = data['status_label_encoded'].nunique()\n",
    "unique_divisions = data['Division_encoded'].nunique()\n",
    "unique_majorgroup = data['MajorGroup_encoded'].nunique()\n",
    "\n",
    "print(\"Number of unique values in 'company_name_encoded' column:\", unique_company_names)\n",
    "print(\"Number of unique values in 'status_label_encoded' column:\", unique_status_labels)\n",
    "print(\"Number of unique values in 'Division_encoded' column:\", unique_divisions)\n",
    "print(\"Number of unique values in 'MajorGroup_encoded' column:\", unique_majorgroup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1abf0ae-6966-43bc-a652-7523ee634cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Division_encoded' column: [3 4 2 8 5 6 1 0 7 9]\n"
     ]
    }
   ],
   "source": [
    "unique_divisions = data['Division_encoded'].unique()\n",
    "print(\"Unique values in 'Division_encoded' column:\", unique_divisions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "381247f3-2cdf-4adf-b51a-e16ec84e1347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with missing values: 3371\n"
     ]
    }
   ],
   "source": [
    "missing_rows_count = data.isnull().any(axis=1).sum()\n",
    "print(\"Number of rows with missing values:\", missing_rows_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b98d5d1a-22e0-4ee6-8fc9-f156a2a97b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5600, 73)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete rows with missing values\n",
    "data_cleaned = data.dropna()\n",
    "# Delete non-numeric columns that are not encoded\n",
    "# List of static columns to drop\n",
    "static_columns_to_drop = [\n",
    "    'company_name', 'status_label', 'Division', 'MajorGroup', 'last_year', 'company_name_encoded',\n",
    "    'Division_encoded', 'MajorGroup_encoded'\n",
    "]\n",
    "\n",
    "# List of dynamic columns to drop (nyse and nasdaq columns for 1 year and 2 years)\n",
    "nyse_nasdaq_columns_to_drop = [f'{exchange}_last{year}year' for exchange in ('nyse', 'nasdaq') for year in (1, 2, 3, 4)]\n",
    "\n",
    "# Add X1_last1year_ycr to X18_last1year_ycr and X1_last2year_ycr to X18_last2year_ycr columns to the list\n",
    "ycr_columns_to_drop = [f'X{i}_last{year}year_ycr' for i in range(1, 19) for year in (1, 2, 3, 4)]\n",
    "\n",
    "# Combine all columns to drop\n",
    "columns_to_drop = static_columns_to_drop + nyse_nasdaq_columns_to_drop + ycr_columns_to_drop\n",
    "\n",
    "# Drop the columns from the data\n",
    "data_cleaned = data_cleaned.drop(columns=columns_to_drop)\n",
    "\n",
    "\n",
    "\n",
    "data_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22f1ba13-272c-4957-96db-dd37c4602510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       X1_last1year  X1_last2year  X1_last3year  X1_last4year  X2_last1year  \\\n",
       "0            942.7         888.5         873.1       954.100       1524.70   \n",
       "1           1107.7         900.2        1077.4      1008.200       1474.50   \n",
       "2          12686.0       13454.0       13582.0      7726.000      21401.00   \n",
       "3         581502.0      353541.0     1037047.0    672072.000    1288165.00   \n",
       "5           6838.0        6642.0        5935.0      7229.000      25088.00   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "8966       10566.0       11738.0        9599.0      9789.000      28278.00   \n",
       "8967        3369.0        9049.0       21381.0        58.314       3466.00   \n",
       "8968        2482.2        2340.6        2071.2      2270.500       9401.50   \n",
       "8969         931.6        1032.7         829.3       735.100       2810.20   \n",
       "8970       82589.0      135207.0       63971.0    105559.000       1625.37   \n",
       "\n",
       "      X2_last2year  X2_last3year  X2_last4year  X3_last1year  X3_last2year  \\\n",
       "0          1504.10      1442.100      1515.000       1413.20      1422.700   \n",
       "1          1343.60      1921.000      1764.800        677.20       600.500   \n",
       "2         27171.00     14341.000         8.153      19334.00        17.589   \n",
       "3        927239.00      1623.383   2003842.000        267.81    229115.000   \n",
       "5         25438.00     25175.000     28571.000      18138.00     16935.000   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "8966      26206.00     23442.000     22757.000      31288.00     26885.000   \n",
       "8967       9198.00     21782.000        59.500        208.00      1077.000   \n",
       "8968      10252.40     10054.100     10190.200        966.70      1833.200   \n",
       "8969       2542.00      2247.400      2285.300       1475.90      1269.600   \n",
       "8970       1736.11   1746235.000   1865926.000      68817.00     66527.000   \n",
       "\n",
       "      ...  X16_last4year  X17_last1year  X17_last2year  X17_last3year  \\\n",
       "0     ...         669.90        1748.30        1767.60       1662.600   \n",
       "1     ...         757.20        1156.60         996.70       1456.400   \n",
       "2     ...           3.49          34.28          28.72      24998.000   \n",
       "3     ...        1120.20      722425.00      653828.00     553617.000   \n",
       "5     ...       25914.00       22170.00       19917.00      23766.000   \n",
       "...   ...            ...            ...            ...            ...   \n",
       "8966  ...       16183.00       39004.00       34484.00      29183.000   \n",
       "8967  ...        9322.00          53.00         545.00          1.316   \n",
       "8968  ...        7271.00        1961.00        3775.90       3585.900   \n",
       "8969  ...        2255.60        2731.70        2408.20       2238.000   \n",
       "8970  ...      880327.00      160513.00      161884.00     169858.000   \n",
       "\n",
       "      X17_last4year  X18_last1year  X18_last2year  X18_last3year  \\\n",
       "0          1594.300       1621.800         1619.4         1525.7   \n",
       "1          1322.200       1035.200          912.0         1283.1   \n",
       "2         23135.000      37001.000        29152.0        23746.0   \n",
       "3          1339.480        681.609       514914.0       390516.0   \n",
       "5         22896.000      20867.000        19655.0        23256.0   \n",
       "...             ...            ...            ...            ...   \n",
       "8966      32735.000      32459.000        27850.0        23059.0   \n",
       "8967          2.828         10.700        13328.0        34947.0   \n",
       "8968       2542.300       1548.300         3017.8         2862.3   \n",
       "8969       2068.100       2112.700         1840.9         1748.0   \n",
       "8970     291153.000      93251.000        92713.0        90807.0   \n",
       "\n",
       "      X18_last4year  status_label_encoded  \n",
       "0           1510.60                     0  \n",
       "1           1154.30                     0  \n",
       "2          21279.00                     0  \n",
       "3        1185651.00                     0  \n",
       "5          20803.00                     1  \n",
       "...             ...                   ...  \n",
       "8966       25531.00                     0  \n",
       "8967       48762.00                     0  \n",
       "8968        2018.30                     0  \n",
       "8969        1624.00                     0  \n",
       "8970          89.02                     0  \n",
       "\n",
       "[5600 rows x 73 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89dd5f1e-dc82-4769-b937-5bb68e3d9f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5124\n",
      "1     476\n",
      "Name: status_label_encoded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "status_counts = data_cleaned['status_label_encoded'].value_counts()\n",
    "print(status_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a330463-b2f8-4aa1-85a6-f2ad40621a69",
   "metadata": {},
   "source": [
    "### 1. RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f159c74-a2f6-46b8-b156-d9db13dd3a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the impact of imbalanced datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317d5616-60a7-4288-b8a2-6630bd5fbe7d",
   "metadata": {},
   "source": [
    "#### 1.1 imbalance dataset + CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90fff82c-02bc-4660-86fb-87d2b8ed60f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9241071428571429\n",
      "Cross-validation Scores: [0.9140625  0.91517857 0.91741071 0.91964286 0.91964286]\n",
      "Mean CV Accuracy: 0.9171875\n",
      "Test Accuracy: 0.9241071428571429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data_cleaned.drop('status_label_encoded', axis=1)\n",
    "y = data_cleaned['status_label_encoded']\n",
    "\n",
    "# Split the data set into training set, validation set and test set\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 80% training, 20% validation\n",
    "\n",
    "# Define a random forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# Train the model on the training set\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_predictions = rf_classifier.predict(X_val)\n",
    "# Calculate accuracy on validation set\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Perform cross-validation on the training set\n",
    "cv_scores = cross_val_score(rf_classifier, X_train_val, y_train_val, cv=5)\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())\n",
    "# Retrain the model on the entire training set\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = rf_classifier.predict(X_test)\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef9d866c-bd00-40bf-9b07-b63d8c2b2bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9241071428571429\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.04597701149425287\n",
      "F1 Score: 0.08602150537634408\n",
      "Micro F1 Score: 0.9241071428571429\n",
      "Macro F1 Score: 0.523215689809737\n",
      "ROC AUC: 0.8044919940804042\n",
      "Confusion Matrix:\n",
      "[[1031    2]\n",
      " [  83    4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, roc_curve, confusion_matrix\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculation precision\n",
    "precision = precision_score(y_test, test_predictions)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, test_predictions)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "y_prob = rf_classifier.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9228af36-d91a-44b9-ba3c-a77f93a903ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80fd8821-7338-45dc-a3e0-949fefa793bc",
   "metadata": {},
   "source": [
    "### 2. XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca37366c-2d39-4c57-9288-5724a2d0fe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1 imbalance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "775f5465-3caa-4d00-908a-bdff4eecaab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.30764\teval-logloss:0.29560\n",
      "[1]\ttrain-logloss:0.29131\teval-logloss:0.28850\n",
      "[2]\ttrain-logloss:0.27595\teval-logloss:0.28059\n",
      "[3]\ttrain-logloss:0.26166\teval-logloss:0.27361\n",
      "[4]\ttrain-logloss:0.24847\teval-logloss:0.26785\n",
      "[5]\ttrain-logloss:0.23602\teval-logloss:0.26273\n",
      "[6]\ttrain-logloss:0.22440\teval-logloss:0.25809\n",
      "[7]\ttrain-logloss:0.21415\teval-logloss:0.25402\n",
      "[8]\ttrain-logloss:0.20399\teval-logloss:0.25012\n",
      "[9]\ttrain-logloss:0.19461\teval-logloss:0.24693\n",
      "[10]\ttrain-logloss:0.18623\teval-logloss:0.24268\n",
      "[11]\ttrain-logloss:0.17829\teval-logloss:0.23992\n",
      "[12]\ttrain-logloss:0.17073\teval-logloss:0.23676\n",
      "[13]\ttrain-logloss:0.16345\teval-logloss:0.23426\n",
      "[14]\ttrain-logloss:0.15670\teval-logloss:0.23267\n",
      "[15]\ttrain-logloss:0.15044\teval-logloss:0.23065\n",
      "[16]\ttrain-logloss:0.14408\teval-logloss:0.22890\n",
      "[17]\ttrain-logloss:0.13814\teval-logloss:0.22699\n",
      "[18]\ttrain-logloss:0.13262\teval-logloss:0.22599\n",
      "[19]\ttrain-logloss:0.12738\teval-logloss:0.22459\n",
      "[20]\ttrain-logloss:0.12230\teval-logloss:0.22334\n",
      "[21]\ttrain-logloss:0.11765\teval-logloss:0.22215\n",
      "[22]\ttrain-logloss:0.11305\teval-logloss:0.22162\n",
      "[23]\ttrain-logloss:0.10864\teval-logloss:0.22048\n",
      "[24]\ttrain-logloss:0.10475\teval-logloss:0.22010\n",
      "[25]\ttrain-logloss:0.10123\teval-logloss:0.21976\n",
      "[26]\ttrain-logloss:0.09775\teval-logloss:0.21884\n",
      "[27]\ttrain-logloss:0.09440\teval-logloss:0.21836\n",
      "[28]\ttrain-logloss:0.09139\teval-logloss:0.21752\n",
      "[29]\ttrain-logloss:0.08832\teval-logloss:0.21679\n",
      "[30]\ttrain-logloss:0.08538\teval-logloss:0.21646\n",
      "[31]\ttrain-logloss:0.08251\teval-logloss:0.21674\n",
      "[32]\ttrain-logloss:0.08006\teval-logloss:0.21563\n",
      "[33]\ttrain-logloss:0.07738\teval-logloss:0.21529\n",
      "[34]\ttrain-logloss:0.07483\teval-logloss:0.21527\n",
      "[35]\ttrain-logloss:0.07242\teval-logloss:0.21451\n",
      "[36]\ttrain-logloss:0.07033\teval-logloss:0.21465\n",
      "[37]\ttrain-logloss:0.06831\teval-logloss:0.21484\n",
      "[38]\ttrain-logloss:0.06637\teval-logloss:0.21452\n",
      "[39]\ttrain-logloss:0.06444\teval-logloss:0.21497\n",
      "[40]\ttrain-logloss:0.06266\teval-logloss:0.21533\n",
      "[41]\ttrain-logloss:0.06096\teval-logloss:0.21535\n",
      "[42]\ttrain-logloss:0.05921\teval-logloss:0.21585\n",
      "[43]\ttrain-logloss:0.05760\teval-logloss:0.21638\n",
      "[44]\ttrain-logloss:0.05603\teval-logloss:0.21591\n",
      "[45]\ttrain-logloss:0.05449\teval-logloss:0.21644\n",
      "Test Accuracy: 0.9258928571428572\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data_cleaned.drop('status_label_encoded', axis=1)\n",
    "y = data_cleaned['status_label_encoded']\n",
    "\n",
    "# Split the data into training + validation and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Further split the training + validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "# Convert data to DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # Binary classification\n",
    "    'eval_metric': 'logloss',         # Logarithmic loss\n",
    "    'eta': 0.07,                       # Learning rate\n",
    "    'max_depth': 60,                   # Maximum depth of the tree\n",
    "    'subsample': 0.9,                 # Subsample ratio of the training instances\n",
    "    'colsample_bytree': 0.9,          # Subsample ratio of columns when constructing each tree\n",
    "    'lambda': 1,                      # L2 regularization term (default is 1)\n",
    "    'alpha': 0,                       # L1 regularization term (default is 0)\n",
    "    'seed': 42                        # Random seed\n",
    "}\n",
    "\n",
    "# Train XGBoost model\n",
    "num_rounds = 100\n",
    "watchlist = [(dtrain, 'train'), (dval, 'eval')]\n",
    "xgb_model = xgb.train(params, dtrain, num_rounds, evals=watchlist, early_stopping_rounds=10)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions_proba = xgb_model.predict(dtest)\n",
    "test_predictions = [1 if x > 0.5 else 0 for x in test_predictions_proba]\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b2d1469-e2c3-4039-b7cb-448d7139d0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9258928571428572\n",
      "Precision: 0.7\n",
      "Recall: 0.08045977011494253\n",
      "F1 Score: 0.14432989690721648\n",
      "Micro F1 Score: 0.9258928571428572\n",
      "Macro F1 Score: 0.5527995728119844\n",
      "ROC AUC: 0.8200865685259983\n",
      "Confusion Matrix:\n",
      "[[1030    3]\n",
      " [  80    7]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, test_predictions)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, test_predictions)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, test_predictions_proba)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4285d6-d191-459f-82e5-af2d11884f3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. GB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59a6df05-e8a0-4152-8526-eabb0e804e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imbalance+cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f705495-0cf3-4d0c-891d-ccd5586d0ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9241071428571429\n",
      "Cross-validation Scores: [0.91964286 0.91741071 0.91741071 0.9140625  0.91852679]\n",
      "Mean CV Accuracy: 0.9174107142857142\n",
      "Test Accuracy: 0.91875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data_cleaned.drop('status_label_encoded', axis=1)\n",
    "y = data_cleaned['status_label_encoded']\n",
    "\n",
    "# Split the data into training + validation and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Further split the training + validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define a Gradient Boosting classifier\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "\n",
    "# Train Gradient Boosting model\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_predictions = gb_classifier.predict(X_val)\n",
    "# Calculate accuracy on validation set\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Perform cross-validation on the train_val set\n",
    "cv_scores = cross_val_score(gb_classifier, X_train_val, y_train_val, cv=5)\n",
    "# Print cross-validat ion scores\n",
    "print(\"Cross-validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = gb_classifier.predict(X_test)\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de63fad9-a98d-4af8-b0df-df411118d900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.91875\n",
      "Macro F1 Score: 0.5453551912568306\n",
      "Test Accuracy: 0.91875\n",
      "Precision: 0.3888888888888889\n",
      "Recall: 0.08045977011494253\n",
      "F1 Score: 0.13333333333333333\n",
      "ROC AUC Score: 0.8248600772217957\n",
      "Confusion Matrix:\n",
      " [[1022   11]\n",
      " [  80    7]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "test_predictions_proba = gb_classifier.predict_proba(X_test)[:, 1]  # Probabilities for positive class\n",
    "roc_auc = roc_auc_score(y_test, test_predictions_proba)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae3d2bb-3c16-4a4c-b420-d4e68d1a1d67",
   "metadata": {},
   "source": [
    "### 4. Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76fec8a7-10c8-4b9e-acb9-a491bb6c1307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalanced + cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b68ffc93-9a1e-4c8c-b462-54a154606896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9330357142857143\n",
      "Cross-validation Scores: [0.921875   0.91517857 0.91964286 0.92299107 0.91741071]\n",
      "Mean CV Accuracy: 0.9194196428571428\n",
      "Test Accuracy: 0.9267857142857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data_cleaned.drop('status_label_encoded', axis=1)\n",
    "y = data_cleaned['status_label_encoded']\n",
    "\n",
    "# Split the data set into training set, validation set and test set\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 80% training, 20% validation\n",
    "\n",
    "# Define a XGBoost base estimator\n",
    "base_estimator = XGBClassifier(n_estimators=100, random_state=42)  #better than base_estimator=DecisionTreeClassifier\n",
    "# Define a bagging classifier\n",
    "bagging_classifier = BaggingClassifier(base_estimator=base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_predictions = bagging_classifier.predict(X_val)\n",
    "# Calculate accuracy on validation set\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Perform cross-validation on the train_val set\n",
    "cv_scores = cross_val_score(bagging_classifier, X_train_val, y_train_val, cv=5)\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = bagging_classifier.predict(X_test)\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fa69893-48ae-4ddf-b419-679fb2d92cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.9267857142857143\n",
      "Macro F1 Score: 0.5865744742149236\n",
      "Test Accuracy: 0.9267857142857143\n",
      "Precision: 0.6470588235294118\n",
      "Recall: 0.12643678160919541\n",
      "F1 Score: 0.21153846153846154\n",
      "ROC AUC Score: 0.825383049036953\n",
      "Confusion Matrix:\n",
      " [[1027    6]\n",
      " [  76   11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, test_predictions)\n",
    "\n",
    "# Calculate micro F1 score\n",
    "micro_f1 = f1_score(y_test, test_predictions, average='micro')\n",
    "print(\"Micro F1 Score:\", micro_f1)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "print(\"Macro F1 Score:\", macro_f1)\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "test_predictions_proba = bagging_classifier.predict_proba(X_test)[:, 1]  # Probabilities for positive class\n",
    "roc_auc = roc_auc_score(y_test, test_predictions_proba)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce603e3-5411-43aa-b4f9-e4ce89eb0602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
